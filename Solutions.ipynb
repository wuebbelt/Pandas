{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "# Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ignore"
    ]
   },
   "source": [
    "1. [Series Attributes and Statistical Methods](#1.-Series-Attributes-and-Statistical-Methods)\n",
    "1. [Series Methods More](#2.-Series-Methods-More)\n",
    "1. [Series Methods More II](#3.-Series-Methods-More-II)\n",
    "1. [String Series Methods](#4.-String-Series-Methods)\n",
    "1. [Datetime Series Methods](#5.-Datetime-Series-Methods)\n",
    "1. [DataFrame Attributes and Methods](#6.-DataFrame-Attributes-and-Methods)\n",
    "1. [DataFrame Descriptive Statistic Methods](#7.-DataFrame-Descriptive-Statistic-Methods)\n",
    "1. [DataFrame Methods More](#8.-DataFrame-Methods-More)\n",
    "1. [DataFrame Methods More II](#9.-DataFrame-Methods-More-II)\n",
    "1. [Changing Data Types](#10.-Changing-Data-Types)\n",
    "1. [Assigning Subsets of Data](#11.-Assigning-Subsets-of-Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Series Attributes and Statistical Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "<span  style=\"color:green; font-size:16px\">Read in the movie dataset with the title as the index and assign the `imdb_score` as a Series to variable `score`. Output the first 5 values.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>color</th>\n",
       "      <th>content_rating</th>\n",
       "      <th>duration</th>\n",
       "      <th>director_name</th>\n",
       "      <th>director_fb</th>\n",
       "      <th>actor1</th>\n",
       "      <th>actor1_fb</th>\n",
       "      <th>actor2</th>\n",
       "      <th>actor2_fb</th>\n",
       "      <th>...</th>\n",
       "      <th>actor3_fb</th>\n",
       "      <th>gross</th>\n",
       "      <th>genres</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>num_voted_users</th>\n",
       "      <th>plot_keywords</th>\n",
       "      <th>language</th>\n",
       "      <th>country</th>\n",
       "      <th>budget</th>\n",
       "      <th>imdb_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Avatar</th>\n",
       "      <td>2009.0</td>\n",
       "      <td>Color</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>178.0</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CCH Pounder</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>Joel David Moore</td>\n",
       "      <td>936.0</td>\n",
       "      <td>...</td>\n",
       "      <td>855.0</td>\n",
       "      <td>760505847.0</td>\n",
       "      <td>Action|Adventure|Fantasy|Sci-Fi</td>\n",
       "      <td>723.0</td>\n",
       "      <td>886204</td>\n",
       "      <td>avatar|future|marine|native|paraplegic</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>237000000.0</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pirates of the Caribbean: At World's End</th>\n",
       "      <td>2007.0</td>\n",
       "      <td>Color</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>169.0</td>\n",
       "      <td>Gore Verbinski</td>\n",
       "      <td>563.0</td>\n",
       "      <td>Johnny Depp</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>Orlando Bloom</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>309404152.0</td>\n",
       "      <td>Action|Adventure|Fantasy</td>\n",
       "      <td>302.0</td>\n",
       "      <td>471220</td>\n",
       "      <td>goddess|marriage ceremony|marriage proposal|pi...</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>300000000.0</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spectre</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>Color</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>148.0</td>\n",
       "      <td>Sam Mendes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Christoph Waltz</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>Rory Kinnear</td>\n",
       "      <td>393.0</td>\n",
       "      <td>...</td>\n",
       "      <td>161.0</td>\n",
       "      <td>200074175.0</td>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "      <td>602.0</td>\n",
       "      <td>275868</td>\n",
       "      <td>bomb|espionage|sequel|spy|terrorist</td>\n",
       "      <td>English</td>\n",
       "      <td>UK</td>\n",
       "      <td>245000000.0</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Dark Knight Rises</th>\n",
       "      <td>2012.0</td>\n",
       "      <td>Color</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>164.0</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>Tom Hardy</td>\n",
       "      <td>27000.0</td>\n",
       "      <td>Christian Bale</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>448130642.0</td>\n",
       "      <td>Action|Thriller</td>\n",
       "      <td>813.0</td>\n",
       "      <td>1144337</td>\n",
       "      <td>deception|imprisonment|lawlessness|police offi...</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>250000000.0</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Star Wars: Episode VII - The Force Awakens</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Doug Walker</td>\n",
       "      <td>131.0</td>\n",
       "      <td>Doug Walker</td>\n",
       "      <td>131.0</td>\n",
       "      <td>Rob Walker</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              year  color content_rating  \\\n",
       "title                                                                      \n",
       "Avatar                                      2009.0  Color          PG-13   \n",
       "Pirates of the Caribbean: At World's End    2007.0  Color          PG-13   \n",
       "Spectre                                     2015.0  Color          PG-13   \n",
       "The Dark Knight Rises                       2012.0  Color          PG-13   \n",
       "Star Wars: Episode VII - The Force Awakens     NaN    NaN            NaN   \n",
       "\n",
       "                                            duration      director_name  \\\n",
       "title                                                                     \n",
       "Avatar                                         178.0      James Cameron   \n",
       "Pirates of the Caribbean: At World's End       169.0     Gore Verbinski   \n",
       "Spectre                                        148.0         Sam Mendes   \n",
       "The Dark Knight Rises                          164.0  Christopher Nolan   \n",
       "Star Wars: Episode VII - The Force Awakens       NaN        Doug Walker   \n",
       "\n",
       "                                            director_fb           actor1  \\\n",
       "title                                                                      \n",
       "Avatar                                              0.0      CCH Pounder   \n",
       "Pirates of the Caribbean: At World's End          563.0      Johnny Depp   \n",
       "Spectre                                             0.0  Christoph Waltz   \n",
       "The Dark Knight Rises                           22000.0        Tom Hardy   \n",
       "Star Wars: Episode VII - The Force Awakens        131.0      Doug Walker   \n",
       "\n",
       "                                            actor1_fb            actor2  \\\n",
       "title                                                                     \n",
       "Avatar                                         1000.0  Joel David Moore   \n",
       "Pirates of the Caribbean: At World's End      40000.0     Orlando Bloom   \n",
       "Spectre                                       11000.0      Rory Kinnear   \n",
       "The Dark Knight Rises                         27000.0    Christian Bale   \n",
       "Star Wars: Episode VII - The Force Awakens      131.0        Rob Walker   \n",
       "\n",
       "                                            actor2_fb  ... actor3_fb  \\\n",
       "title                                                  ...             \n",
       "Avatar                                          936.0  ...     855.0   \n",
       "Pirates of the Caribbean: At World's End       5000.0  ...    1000.0   \n",
       "Spectre                                         393.0  ...     161.0   \n",
       "The Dark Knight Rises                         23000.0  ...   23000.0   \n",
       "Star Wars: Episode VII - The Force Awakens       12.0  ...       NaN   \n",
       "\n",
       "                                                  gross  \\\n",
       "title                                                     \n",
       "Avatar                                      760505847.0   \n",
       "Pirates of the Caribbean: At World's End    309404152.0   \n",
       "Spectre                                     200074175.0   \n",
       "The Dark Knight Rises                       448130642.0   \n",
       "Star Wars: Episode VII - The Force Awakens          NaN   \n",
       "\n",
       "                                                                     genres  \\\n",
       "title                                                                         \n",
       "Avatar                                      Action|Adventure|Fantasy|Sci-Fi   \n",
       "Pirates of the Caribbean: At World's End           Action|Adventure|Fantasy   \n",
       "Spectre                                           Action|Adventure|Thriller   \n",
       "The Dark Knight Rises                                       Action|Thriller   \n",
       "Star Wars: Episode VII - The Force Awakens                      Documentary   \n",
       "\n",
       "                                           num_reviews  num_voted_users  \\\n",
       "title                                                                     \n",
       "Avatar                                           723.0           886204   \n",
       "Pirates of the Caribbean: At World's End         302.0           471220   \n",
       "Spectre                                          602.0           275868   \n",
       "The Dark Knight Rises                            813.0          1144337   \n",
       "Star Wars: Episode VII - The Force Awakens         NaN                8   \n",
       "\n",
       "                                                                                plot_keywords  \\\n",
       "title                                                                                           \n",
       "Avatar                                                 avatar|future|marine|native|paraplegic   \n",
       "Pirates of the Caribbean: At World's End    goddess|marriage ceremony|marriage proposal|pi...   \n",
       "Spectre                                                   bomb|espionage|sequel|spy|terrorist   \n",
       "The Dark Knight Rises                       deception|imprisonment|lawlessness|police offi...   \n",
       "Star Wars: Episode VII - The Force Awakens                                                NaN   \n",
       "\n",
       "                                           language country       budget  \\\n",
       "title                                                                      \n",
       "Avatar                                      English     USA  237000000.0   \n",
       "Pirates of the Caribbean: At World's End    English     USA  300000000.0   \n",
       "Spectre                                     English      UK  245000000.0   \n",
       "The Dark Knight Rises                       English     USA  250000000.0   \n",
       "Star Wars: Episode VII - The Force Awakens      NaN     NaN          NaN   \n",
       "\n",
       "                                            imdb_score  \n",
       "title                                                   \n",
       "Avatar                                             7.9  \n",
       "Pirates of the Caribbean: At World's End           7.1  \n",
       "Spectre                                            6.8  \n",
       "The Dark Knight Rises                              8.5  \n",
       "Star Wars: Episode VII - The Force Awakens         7.1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie = pd.read_csv('../data/movie.csv', index_col='title')\n",
    "movie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "Avatar                                        7.9\n",
       "Pirates of the Caribbean: At World's End      7.1\n",
       "Spectre                                       6.8\n",
       "The Dark Knight Rises                         8.5\n",
       "Star Wars: Episode VII - The Force Awakens    7.1\n",
       "Name: imdb_score, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = movie['imdb_score']\n",
    "score.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "<span  style=\"color:green; font-size:16px\">What is the data type of `score` and how many values does it contain?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4916"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or use the `len` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4916"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "<span  style=\"color:green; font-size:16px\">What is the maximum and minimum score?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "<span  style=\"color:green; font-size:16px\">How many missing values are there in the `score`?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "<span  style=\"color:green; font-size:16px\">Read he docstrings on how the `rank` method works and then rank the first 10 values in `score` from highest to lowest.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "Avatar                                         2.0\n",
       "Pirates of the Caribbean: At World's End       6.5\n",
       "Spectre                                        8.0\n",
       "The Dark Knight Rises                          1.0\n",
       "Star Wars: Episode VII - The Force Awakens     6.5\n",
       "John Carter                                    9.0\n",
       "Spider-Man 3                                  10.0\n",
       "Tangled                                        3.0\n",
       "Avengers: Age of Ultron                        4.5\n",
       "Harry Potter and the Half-Blood Prince         4.5\n",
       "Name: imdb_score, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.head(10).rank(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can also assign the head to a variable and then call `rank`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_head = score.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "Avatar                                         9.0\n",
       "Pirates of the Caribbean: At World's End       4.5\n",
       "Spectre                                        3.0\n",
       "The Dark Knight Rises                         10.0\n",
       "Star Wars: Episode VII - The Force Awakens     4.5\n",
       "John Carter                                    2.0\n",
       "Spider-Man 3                                   1.0\n",
       "Tangled                                        8.0\n",
       "Avengers: Age of Ultron                        6.5\n",
       "Harry Potter and the Half-Blood Prince         6.5\n",
       "Name: imdb_score, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_head.rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "<span  style=\"color:green; font-size:16px\">How many movies have scores greater than 6? (Remember that True/False evaluates to 1/0)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3368"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(score > 6).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "<span  style=\"color:green; font-size:16px\">How many movies have scores greater than 4 and less than 7?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3021"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt1 = score > 4\n",
    "filt2 = score < 7\n",
    "filt = filt1 & filt2\n",
    "\n",
    "filt.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or in one line of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3021"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((score > 4) & (score < 7)).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8\n",
    "<span  style=\"color:green; font-size:16px\">Find the difference between the median and mean of the scores.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16257119609438497"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.median() - score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9\n",
    "<span  style=\"color:green; font-size:16px\">Add 1 to every value of `score` and then calculate the median.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(score + 1).median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10\n",
    "<span  style=\"color:green; font-size:16px\">Calculate the median of `score` and add 1 to this. Why is this value the same as Exercise 9?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.6"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.median() + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11\n",
    "<span  style=\"color:green; font-size:16px\">Return a Series that has only scores above the 99.9th percentile</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "The Shawshank Redemption    9.3\n",
       "Towering Inferno            9.5\n",
       "Dekalog                     9.1\n",
       "The Godfather               9.2\n",
       "Kickboxer: Vengeance        9.1\n",
       "Name: imdb_score, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt = score > score.quantile(.999)\n",
    "score[filt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Series Methods More"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "<span  style=\"color:green; font-size:16px\">What percentage of actor 1 Facebook likes are missing?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>color</th>\n",
       "      <th>content_rating</th>\n",
       "      <th>duration</th>\n",
       "      <th>director_name</th>\n",
       "      <th>director_fb</th>\n",
       "      <th>actor1</th>\n",
       "      <th>actor1_fb</th>\n",
       "      <th>actor2</th>\n",
       "      <th>actor2_fb</th>\n",
       "      <th>...</th>\n",
       "      <th>actor3_fb</th>\n",
       "      <th>gross</th>\n",
       "      <th>genres</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>num_voted_users</th>\n",
       "      <th>plot_keywords</th>\n",
       "      <th>language</th>\n",
       "      <th>country</th>\n",
       "      <th>budget</th>\n",
       "      <th>imdb_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Avatar</th>\n",
       "      <td>2009.0</td>\n",
       "      <td>Color</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>178.0</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CCH Pounder</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>Joel David Moore</td>\n",
       "      <td>936.0</td>\n",
       "      <td>...</td>\n",
       "      <td>855.0</td>\n",
       "      <td>760505847.0</td>\n",
       "      <td>Action|Adventure|Fantasy|Sci-Fi</td>\n",
       "      <td>723.0</td>\n",
       "      <td>886204</td>\n",
       "      <td>avatar|future|marine|native|paraplegic</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>237000000.0</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pirates of the Caribbean: At World's End</th>\n",
       "      <td>2007.0</td>\n",
       "      <td>Color</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>169.0</td>\n",
       "      <td>Gore Verbinski</td>\n",
       "      <td>563.0</td>\n",
       "      <td>Johnny Depp</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>Orlando Bloom</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>309404152.0</td>\n",
       "      <td>Action|Adventure|Fantasy</td>\n",
       "      <td>302.0</td>\n",
       "      <td>471220</td>\n",
       "      <td>goddess|marriage ceremony|marriage proposal|pi...</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>300000000.0</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spectre</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>Color</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>148.0</td>\n",
       "      <td>Sam Mendes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Christoph Waltz</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>Rory Kinnear</td>\n",
       "      <td>393.0</td>\n",
       "      <td>...</td>\n",
       "      <td>161.0</td>\n",
       "      <td>200074175.0</td>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "      <td>602.0</td>\n",
       "      <td>275868</td>\n",
       "      <td>bomb|espionage|sequel|spy|terrorist</td>\n",
       "      <td>English</td>\n",
       "      <td>UK</td>\n",
       "      <td>245000000.0</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Dark Knight Rises</th>\n",
       "      <td>2012.0</td>\n",
       "      <td>Color</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>164.0</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>Tom Hardy</td>\n",
       "      <td>27000.0</td>\n",
       "      <td>Christian Bale</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>448130642.0</td>\n",
       "      <td>Action|Thriller</td>\n",
       "      <td>813.0</td>\n",
       "      <td>1144337</td>\n",
       "      <td>deception|imprisonment|lawlessness|police offi...</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>250000000.0</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Star Wars: Episode VII - The Force Awakens</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Doug Walker</td>\n",
       "      <td>131.0</td>\n",
       "      <td>Doug Walker</td>\n",
       "      <td>131.0</td>\n",
       "      <td>Rob Walker</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              year  color content_rating  \\\n",
       "title                                                                      \n",
       "Avatar                                      2009.0  Color          PG-13   \n",
       "Pirates of the Caribbean: At World's End    2007.0  Color          PG-13   \n",
       "Spectre                                     2015.0  Color          PG-13   \n",
       "The Dark Knight Rises                       2012.0  Color          PG-13   \n",
       "Star Wars: Episode VII - The Force Awakens     NaN    NaN            NaN   \n",
       "\n",
       "                                            duration      director_name  \\\n",
       "title                                                                     \n",
       "Avatar                                         178.0      James Cameron   \n",
       "Pirates of the Caribbean: At World's End       169.0     Gore Verbinski   \n",
       "Spectre                                        148.0         Sam Mendes   \n",
       "The Dark Knight Rises                          164.0  Christopher Nolan   \n",
       "Star Wars: Episode VII - The Force Awakens       NaN        Doug Walker   \n",
       "\n",
       "                                            director_fb           actor1  \\\n",
       "title                                                                      \n",
       "Avatar                                              0.0      CCH Pounder   \n",
       "Pirates of the Caribbean: At World's End          563.0      Johnny Depp   \n",
       "Spectre                                             0.0  Christoph Waltz   \n",
       "The Dark Knight Rises                           22000.0        Tom Hardy   \n",
       "Star Wars: Episode VII - The Force Awakens        131.0      Doug Walker   \n",
       "\n",
       "                                            actor1_fb            actor2  \\\n",
       "title                                                                     \n",
       "Avatar                                         1000.0  Joel David Moore   \n",
       "Pirates of the Caribbean: At World's End      40000.0     Orlando Bloom   \n",
       "Spectre                                       11000.0      Rory Kinnear   \n",
       "The Dark Knight Rises                         27000.0    Christian Bale   \n",
       "Star Wars: Episode VII - The Force Awakens      131.0        Rob Walker   \n",
       "\n",
       "                                            actor2_fb  ... actor3_fb  \\\n",
       "title                                                  ...             \n",
       "Avatar                                          936.0  ...     855.0   \n",
       "Pirates of the Caribbean: At World's End       5000.0  ...    1000.0   \n",
       "Spectre                                         393.0  ...     161.0   \n",
       "The Dark Knight Rises                         23000.0  ...   23000.0   \n",
       "Star Wars: Episode VII - The Force Awakens       12.0  ...       NaN   \n",
       "\n",
       "                                                  gross  \\\n",
       "title                                                     \n",
       "Avatar                                      760505847.0   \n",
       "Pirates of the Caribbean: At World's End    309404152.0   \n",
       "Spectre                                     200074175.0   \n",
       "The Dark Knight Rises                       448130642.0   \n",
       "Star Wars: Episode VII - The Force Awakens          NaN   \n",
       "\n",
       "                                                                     genres  \\\n",
       "title                                                                         \n",
       "Avatar                                      Action|Adventure|Fantasy|Sci-Fi   \n",
       "Pirates of the Caribbean: At World's End           Action|Adventure|Fantasy   \n",
       "Spectre                                           Action|Adventure|Thriller   \n",
       "The Dark Knight Rises                                       Action|Thriller   \n",
       "Star Wars: Episode VII - The Force Awakens                      Documentary   \n",
       "\n",
       "                                           num_reviews  num_voted_users  \\\n",
       "title                                                                     \n",
       "Avatar                                           723.0           886204   \n",
       "Pirates of the Caribbean: At World's End         302.0           471220   \n",
       "Spectre                                          602.0           275868   \n",
       "The Dark Knight Rises                            813.0          1144337   \n",
       "Star Wars: Episode VII - The Force Awakens         NaN                8   \n",
       "\n",
       "                                                                                plot_keywords  \\\n",
       "title                                                                                           \n",
       "Avatar                                                 avatar|future|marine|native|paraplegic   \n",
       "Pirates of the Caribbean: At World's End    goddess|marriage ceremony|marriage proposal|pi...   \n",
       "Spectre                                                   bomb|espionage|sequel|spy|terrorist   \n",
       "The Dark Knight Rises                       deception|imprisonment|lawlessness|police offi...   \n",
       "Star Wars: Episode VII - The Force Awakens                                                NaN   \n",
       "\n",
       "                                           language country       budget  \\\n",
       "title                                                                      \n",
       "Avatar                                      English     USA  237000000.0   \n",
       "Pirates of the Caribbean: At World's End    English     USA  300000000.0   \n",
       "Spectre                                     English      UK  245000000.0   \n",
       "The Dark Knight Rises                       English     USA  250000000.0   \n",
       "Star Wars: Episode VII - The Force Awakens      NaN     NaN          NaN   \n",
       "\n",
       "                                            imdb_score  \n",
       "title                                                   \n",
       "Avatar                                             7.9  \n",
       "Pirates of the Caribbean: At World's End           7.1  \n",
       "Spectre                                            6.8  \n",
       "The Dark Knight Rises                              8.5  \n",
       "Star Wars: Episode VII - The Force Awakens         7.1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie = pd.read_csv('../data/movie.csv', index_col='title')\n",
    "movie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0014239218877135883"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie['actor1_fb'].isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "<span  style=\"color:green; font-size:16px\">Use the `notna` method to find the number of non-missing values in the actor 1 Facebook like column. Verify this number is the same as the `count` method.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4909"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie['actor1_fb'].notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4909"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie['actor1_fb'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "<span  style=\"color:green; font-size:16px\">Fill the missing values of `actor1_fb` with the maximum of `actor2_fb`. Save this result to variable `actor1_fb_full`</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137000.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_fb2 = movie['actor2_fb'].max()\n",
    "max_fb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "Avatar                                         1000.0\n",
       "Pirates of the Caribbean: At World's End      40000.0\n",
       "Spectre                                       11000.0\n",
       "The Dark Knight Rises                         27000.0\n",
       "Star Wars: Episode VII - The Force Awakens      131.0\n",
       "Name: actor1_fb, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor1_fb_full = movie['actor1_fb'].fillna(max_fb2)\n",
    "actor1_fb_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "<span  style=\"color:green; font-size:16px\">Verify the results of Exercise 3 by selecting just the values of `actor1_fb_full` that were filled by `actor2_fb`.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "Pink Ribbons, Inc.         137000.0\n",
       "Sex with Strangers         137000.0\n",
       "The Harvest/La Cosecha     137000.0\n",
       "Ayurveda: Art of Being     137000.0\n",
       "The Brain That Sings       137000.0\n",
       "The Blood of My Brother    137000.0\n",
       "Counting                   137000.0\n",
       "Name: actor1_fb, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt = movie['actor1_fb'].isna()\n",
    "actor1_fb_full[filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137000.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie['actor2_fb'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Series Methods More II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "<span  style=\"color:green; font-size:16px\">Randomly sample the `actor1_fb` column as a Series with replacement to select three values. Use random state 54321.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "Firestarter          695.0\n",
       "November             308.0\n",
       "Waltz with Bashir     56.0\n",
       "Name: actor1_fb, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie['actor1_fb'].sample(3, replace=True, random_state=54321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "<span  style=\"color:green; font-size:16px\">How many unique directors are there?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2397"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie['director_name'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "<span  style=\"color:green; font-size:16px\">Select the `year` column, sort it, and drop any duplicates?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "Intolerance: Love's Struggle Throughout the Ages           1916.0\n",
       "Over the Hill to the Poorhouse                             1920.0\n",
       "The Big Parade                                             1925.0\n",
       "Metropolis                                                 1927.0\n",
       "The Broadway Melody                                        1929.0\n",
       "Hell's Angels                                              1930.0\n",
       "A Farewell to Arms                                         1932.0\n",
       "42nd Street                                                1933.0\n",
       "It Happened One Night                                      1934.0\n",
       "Top Hat                                                    1935.0\n",
       "The Charge of the Light Brigade                            1936.0\n",
       "The Prisoner of Zenda                                      1937.0\n",
       "You Can't Take It with You                                 1938.0\n",
       "Gone with the Wind                                         1939.0\n",
       "Rebecca                                                    1940.0\n",
       "How Green Was My Valley                                    1941.0\n",
       "Bambi                                                      1942.0\n",
       "A Guy Named Joe                                            1943.0\n",
       "Bathing Beauty                                             1944.0\n",
       "The Valley of Decision                                     1945.0\n",
       "It's a Wonderful Life                                      1946.0\n",
       "The Lady from Shanghai                                     1947.0\n",
       "Red River                                                  1948.0\n",
       "Sands of Iwo Jima                                          1949.0\n",
       "Annie Get Your Gun                                         1950.0\n",
       "Show Boat                                                  1951.0\n",
       "Singin' in the Rain                                        1952.0\n",
       "Niagara                                                    1953.0\n",
       "The Egyptian                                               1954.0\n",
       "Ordet                                                      1955.0\n",
       "                                                            ...  \n",
       "Phantasm II                                                1988.0\n",
       "Roger & Me                                                 1989.0\n",
       "Gremlins 2: The New Batch                                  1990.0\n",
       "Teenage Mutant Ninja Turtles II: The Secret of the Ooze    1991.0\n",
       "Unforgiven                                                 1992.0\n",
       "Nowhere to Run                                             1993.0\n",
       "Exotica                                                    1994.0\n",
       "The Scarlet Letter                                         1995.0\n",
       "Eraser                                                     1996.0\n",
       "Speed 2: Cruise Control                                    1997.0\n",
       "Stiff Upper Lips                                           1998.0\n",
       "Dudley Do-Right                                            1999.0\n",
       "Center Stage                                               2000.0\n",
       "Life as a House                                            2001.0\n",
       "Poolhall Junkies                                           2002.0\n",
       "Wonderland                                                 2003.0\n",
       "Hotel Rwanda                                               2004.0\n",
       "Goal! The Dream Begins                                     2005.0\n",
       "Just My Luck                                               2006.0\n",
       "Lucky You                                                  2007.0\n",
       "Synecdoche, New York                                       2008.0\n",
       "New in Town                                                2009.0\n",
       "The Book of Eli                                            2010.0\n",
       "Soul Surfer                                                2011.0\n",
       "Man on a Ledge                                             2012.0\n",
       "The Wolverine                                              2013.0\n",
       "An American in Hollywood                                   2014.0\n",
       "The Lovers                                                 2015.0\n",
       "Pete's Dragon                                              2016.0\n",
       "Star Wars: Episode VII - The Force Awakens                    NaN\n",
       "Name: year, Length: 92, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie['year'].sort_values().drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "<span  style=\"color:green; font-size:16px\">Get the same result as Exercise 3 by dropping duplicates first and then sort. Which method is faster?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faster to drop duplicates then sort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.84 ms ± 332 µs per loop (mean ± std. dev. of 7 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 5 movie['year'].drop_duplicates().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.89 ms ± 1.15 ms per loop (mean ± std. dev. of 7 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 5 movie['year'].sort_values().drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. String Series Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "<span  style=\"color:green; font-size:16px\">Read in the movie dataset and set the title as the index. Assign the actor 1 column to its own Series variable. Make sure to drop missing values from this Series before assigning it.\n",
    "\n",
    "Which actor 1 has appeared in the most movies? Can you write an expression that returns this actors name as a string?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Robert De Niro    48\n",
       "Johnny Depp       36\n",
       "Nicolas Cage      32\n",
       "Matt Damon        29\n",
       "J.K. Simmons      29\n",
       "Name: actor1, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie = pd.read_csv('../data/movie.csv', index_col='title')\n",
    "actor1 = movie['actor1'].dropna()\n",
    "actor1.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Robert De Niro'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor1.value_counts().index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "<span  style=\"color:green; font-size:16px\">What percent of movies have the top 100 most frequent actor 1's appeared in?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.325117131798737"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor1.value_counts(normalize=True).iloc[:100].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "<span  style=\"color:green; font-size:16px\">How many actor 1's have appeared in exactly one movie?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1379"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(actor1.value_counts() == 1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "<span  style=\"color:green; font-size:16px\">How many actor 1's have more than 3 e's in their name? Output a unique array of just these actor names so we can manually verify them.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Jennifer Lawrence', 'Keanu Reeves', 'Seychelle Gabriel',\n",
       "       'Jeremy Renner', 'Amber Stevens West', 'Peter Greene',\n",
       "       'Steven Anthony Lawrence', 'Cedric the Entertainer',\n",
       "       'Sean Pertwee', 'Xander Berkeley', 'Kathleen Freeman',\n",
       "       'Pierre Perrier', 'Catherine Deneuve', 'George Kennedy',\n",
       "       'Leighton Meester', 'Steve Guttenberg', 'Emmanuelle Seigner',\n",
       "       'Jurnee Smollett-Bell', 'Steve Oedekerk',\n",
       "       'Johannes Silberschneider', 'Bernadette Peters',\n",
       "       'Jacqueline McKenzie', 'Dee Bradley Baker', 'Jennifer Freeman',\n",
       "       'Gene Tierney', 'Roscoe Lee Browne', 'Phoebe Legere',\n",
       "       'Eric Sheffer Stevens', 'Michael Greyeyes', 'Steven Weber',\n",
       "       'George Newbern', 'Florence Henderson', 'Michelle Simone Miller',\n",
       "       'Chemeeka Walker', 'Fereshteh Sadre Orafaiy'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt = actor1.str.count('e') > 3\n",
    "unique_e = actor1[filt].unique()\n",
    "unique_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be more exact and account for both upper and lowercase letters, use the regular expression, `[eE]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Jennifer Lawrence', 'Keanu Reeves', 'Seychelle Gabriel',\n",
       "       'Jeremy Renner', 'Amber Stevens West', 'Rupert Everett',\n",
       "       'Peter Greene', 'Eileen Brennan', 'Steven Anthony Lawrence',\n",
       "       'Cedric the Entertainer', 'Sean Pertwee', 'Xander Berkeley',\n",
       "       'Eddie Redmayne', 'Jennifer Ehle', 'Kathleen Freeman',\n",
       "       'Alden Ehrenreich', 'Pierre Perrier', 'Catherine Deneuve',\n",
       "       'George Kennedy', 'Leighton Meester', 'Steve Guttenberg',\n",
       "       'Ernie Reyes Jr.', 'Emmanuelle Vaugier', 'Emmanuelle Seigner',\n",
       "       'Jurnee Smollett-Bell', 'Steve Oedekerk',\n",
       "       'Johannes Silberschneider', 'Bernadette Peters',\n",
       "       'Jacqueline McKenzie', 'Dee Bradley Baker', 'Jennifer Freeman',\n",
       "       'Eugenio Derbez', 'Gene Tierney', 'Roscoe Lee Browne',\n",
       "       'Ed Speleers', 'Joe Estevez', 'Phoebe Legere',\n",
       "       'Eric Sheffer Stevens', 'Michael Greyeyes', 'Steven Weber',\n",
       "       'George Newbern', 'Florence Henderson', 'Michelle Simone Miller',\n",
       "       'Chemeeka Walker', 'Fereshteh Sadre Orafaiy'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt = actor1.str.count('[eE]') > 3\n",
    "unique_eE = actor1[filt].unique()\n",
    "unique_eE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_eE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "<span  style=\"color:green; font-size:16px\">Get a unique list of all actors that have the name 'Johnson' as part of their name. Note: When using the </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Don Johnson', 'Dwayne Johnson', 'Richard Johnson', 'Eric Johnson',\n",
       "       'Bill Johnson', 'Nicole Randall Johnson', 'R. Brandon Johnson'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt = actor1.str.contains('Johnson')\n",
    "actor1[filt].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "<span  style=\"color:green; font-size:16px\">How many actor 1 names end in 'x'?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor1.str.endswith('x').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "<span  style=\"color:green; font-size:16px\">The Pandas string methods overlap with the builtin Python string methods. Find all the public method names that are in-common to both. Then find the public methods that are unique to each.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_str = {method for method in dir(str) if method[0] != '_'}\n",
    "pandas_str = {method for method in dir(actor1.str) if method[0] != '_'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'capitalize',\n",
       " 'center',\n",
       " 'count',\n",
       " 'encode',\n",
       " 'endswith',\n",
       " 'find',\n",
       " 'index',\n",
       " 'isalnum',\n",
       " 'isalpha',\n",
       " 'isdecimal',\n",
       " 'isdigit',\n",
       " 'islower',\n",
       " 'isnumeric',\n",
       " 'isspace',\n",
       " 'istitle',\n",
       " 'isupper',\n",
       " 'join',\n",
       " 'ljust',\n",
       " 'lower',\n",
       " 'lstrip',\n",
       " 'partition',\n",
       " 'replace',\n",
       " 'rfind',\n",
       " 'rindex',\n",
       " 'rjust',\n",
       " 'rpartition',\n",
       " 'rsplit',\n",
       " 'rstrip',\n",
       " 'split',\n",
       " 'startswith',\n",
       " 'strip',\n",
       " 'swapcase',\n",
       " 'title',\n",
       " 'translate',\n",
       " 'upper',\n",
       " 'zfill'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_str & pandas_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'casefold',\n",
       " 'expandtabs',\n",
       " 'format',\n",
       " 'format_map',\n",
       " 'isascii',\n",
       " 'isidentifier',\n",
       " 'isprintable',\n",
       " 'maketrans',\n",
       " 'splitlines'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_str - pandas_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat',\n",
       " 'contains',\n",
       " 'decode',\n",
       " 'extract',\n",
       " 'extractall',\n",
       " 'findall',\n",
       " 'get',\n",
       " 'get_dummies',\n",
       " 'len',\n",
       " 'match',\n",
       " 'normalize',\n",
       " 'pad',\n",
       " 'repeat',\n",
       " 'slice',\n",
       " 'slice_replace',\n",
       " 'wrap'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_str - python_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Datetime Series Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes = pd.read_csv('../data/bikes.csv', parse_dates=['starttime', 'stoptime'])\n",
    "start = bikes['starttime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "<span  style=\"color:green; font-size:16px\">What percentage of bike rides happen in January?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "August       0.137\n",
       "July         0.132\n",
       "September    0.130\n",
       "June         0.121\n",
       "October      0.111\n",
       "May          0.086\n",
       "November     0.071\n",
       "April        0.064\n",
       "December     0.045\n",
       "March        0.044\n",
       "February     0.030\n",
       "January      0.027\n",
       "Name: starttime, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.7%\n",
    "start.dt.month_name().value_counts(normalize=True).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "<span  style=\"color:green; font-size:16px\">What percentage of bike rides happen on the weekend?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19692946555131866"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start.dt.weekday.isin([5, 6]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19692946555131866"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(start.dt.weekday > 4).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "<span  style=\"color:green; font-size:16px\">What percentage of bike rides happen on the last day of the month?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.031563816406795904"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start.dt.is_month_end.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "<span  style=\"color:green; font-size:16px\">We would expect that the value of the minutes recorded for each starting ride is approximately random. Can you show some data that confirms or rejects this?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution looks quite uniform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12    0.017968\n",
       "6     0.017928\n",
       "8     0.017868\n",
       "18    0.017808\n",
       "43    0.017629\n",
       "21    0.017549\n",
       "10    0.017529\n",
       "48    0.017509\n",
       "44    0.017449\n",
       "15    0.017409\n",
       "53    0.017349\n",
       "17    0.017329\n",
       "37    0.017309\n",
       "13    0.017289\n",
       "19    0.017269\n",
       "33    0.017229\n",
       "42    0.017229\n",
       "39    0.017189\n",
       "24    0.017189\n",
       "22    0.017110\n",
       "34    0.017070\n",
       "29    0.017070\n",
       "45    0.016950\n",
       "5     0.016890\n",
       "36    0.016870\n",
       "11    0.016870\n",
       "14    0.016870\n",
       "49    0.016850\n",
       "47    0.016830\n",
       "30    0.016810\n",
       "16    0.016710\n",
       "32    0.016670\n",
       "38    0.016630\n",
       "1     0.016630\n",
       "40    0.016531\n",
       "7     0.016491\n",
       "2     0.016471\n",
       "46    0.016471\n",
       "4     0.016391\n",
       "23    0.016331\n",
       "54    0.016311\n",
       "57    0.016291\n",
       "3     0.016251\n",
       "28    0.016091\n",
       "35    0.016071\n",
       "59    0.016071\n",
       "56    0.016031\n",
       "0     0.015932\n",
       "58    0.015912\n",
       "50    0.015872\n",
       "31    0.015872\n",
       "55    0.015852\n",
       "9     0.015812\n",
       "27    0.015812\n",
       "41    0.015712\n",
       "20    0.015612\n",
       "25    0.015512\n",
       "52    0.015253\n",
       "51    0.015213\n",
       "26    0.014973\n",
       "Name: starttime, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start.dt.minute.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "<span  style=\"color:green; font-size:16px\">Assign the length of the ride to `ride_length`. Then find the percentage of rides that lasted longer than 30 minutes.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = bikes['stoptime']\n",
    "ride_length = stop - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019625067380063487"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ride_length.dt.total_seconds() > (60 * 30)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. DataFrame Attributes and Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "<span  style=\"color:green; font-size:16px\">Select only the float columns from the `college` DataFrame. How many are there?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7535, 20)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college = pd.read_csv('../data/college.csv', index_col='instnm')\n",
    "college.select_dtypes('float').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 20 float columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "<span  style=\"color:green; font-size:16px\">When you call the `info` method on a DataFrame, one of the very last items that gets returned is the count of columns for each data type. Can you think of a different combination of Pandas operations that would return this as a Series. Use just one line of code.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    20\n",
       "object      4\n",
       "int64       2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. DataFrame Descriptive Statistic Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "college = pd.read_csv('../data/college.csv', index_col='instnm')\n",
    "college_race = college.loc[:, 'ugds_white':'ugds_unkn']\n",
    "\n",
    "movie = pd.read_csv('../data/movie.csv', index_col='title')\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "<span  style=\"color:green; font-size:16px\">Read in the movie dataset and calculate the mean of each actor Facebook like column. Which actor (1, 2, or 3) has the highest mean?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>color</th>\n",
       "      <th>content_rating</th>\n",
       "      <th>duration</th>\n",
       "      <th>director_name</th>\n",
       "      <th>director_fb</th>\n",
       "      <th>actor1</th>\n",
       "      <th>actor1_fb</th>\n",
       "      <th>actor2</th>\n",
       "      <th>actor2_fb</th>\n",
       "      <th>actor3</th>\n",
       "      <th>actor3_fb</th>\n",
       "      <th>gross</th>\n",
       "      <th>genres</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>num_voted_users</th>\n",
       "      <th>plot_keywords</th>\n",
       "      <th>language</th>\n",
       "      <th>country</th>\n",
       "      <th>budget</th>\n",
       "      <th>imdb_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Avatar</th>\n",
       "      <td>2009.0</td>\n",
       "      <td>Color</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>178.0</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CCH Pounder</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>Joel David Moore</td>\n",
       "      <td>936.0</td>\n",
       "      <td>Wes Studi</td>\n",
       "      <td>855.0</td>\n",
       "      <td>760505847.0</td>\n",
       "      <td>Action|Adventure|Fantasy|Sci-Fi</td>\n",
       "      <td>723.0</td>\n",
       "      <td>886204</td>\n",
       "      <td>avatar|future|marine|native|paraplegic</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>237000000.0</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pirates of the Caribbean: At World's End</th>\n",
       "      <td>2007.0</td>\n",
       "      <td>Color</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>169.0</td>\n",
       "      <td>Gore Verbinski</td>\n",
       "      <td>563.0</td>\n",
       "      <td>Johnny Depp</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>Orlando Bloom</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>Jack Davenport</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>309404152.0</td>\n",
       "      <td>Action|Adventure|Fantasy</td>\n",
       "      <td>302.0</td>\n",
       "      <td>471220</td>\n",
       "      <td>goddess|marriage ceremony|marriage proposal|pi...</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>300000000.0</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spectre</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>Color</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>148.0</td>\n",
       "      <td>Sam Mendes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Christoph Waltz</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>Rory Kinnear</td>\n",
       "      <td>393.0</td>\n",
       "      <td>Stephanie Sigman</td>\n",
       "      <td>161.0</td>\n",
       "      <td>200074175.0</td>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "      <td>602.0</td>\n",
       "      <td>275868</td>\n",
       "      <td>bomb|espionage|sequel|spy|terrorist</td>\n",
       "      <td>English</td>\n",
       "      <td>UK</td>\n",
       "      <td>245000000.0</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Dark Knight Rises</th>\n",
       "      <td>2012.0</td>\n",
       "      <td>Color</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>164.0</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>Tom Hardy</td>\n",
       "      <td>27000.0</td>\n",
       "      <td>Christian Bale</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>Joseph Gordon-Levitt</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>448130642.0</td>\n",
       "      <td>Action|Thriller</td>\n",
       "      <td>813.0</td>\n",
       "      <td>1144337</td>\n",
       "      <td>deception|imprisonment|lawlessness|police offi...</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>250000000.0</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Star Wars: Episode VII - The Force Awakens</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Doug Walker</td>\n",
       "      <td>131.0</td>\n",
       "      <td>Doug Walker</td>\n",
       "      <td>131.0</td>\n",
       "      <td>Rob Walker</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              year  color content_rating  \\\n",
       "title                                                                      \n",
       "Avatar                                      2009.0  Color          PG-13   \n",
       "Pirates of the Caribbean: At World's End    2007.0  Color          PG-13   \n",
       "Spectre                                     2015.0  Color          PG-13   \n",
       "The Dark Knight Rises                       2012.0  Color          PG-13   \n",
       "Star Wars: Episode VII - The Force Awakens     NaN    NaN            NaN   \n",
       "\n",
       "                                            duration      director_name  \\\n",
       "title                                                                     \n",
       "Avatar                                         178.0      James Cameron   \n",
       "Pirates of the Caribbean: At World's End       169.0     Gore Verbinski   \n",
       "Spectre                                        148.0         Sam Mendes   \n",
       "The Dark Knight Rises                          164.0  Christopher Nolan   \n",
       "Star Wars: Episode VII - The Force Awakens       NaN        Doug Walker   \n",
       "\n",
       "                                            director_fb           actor1  \\\n",
       "title                                                                      \n",
       "Avatar                                              0.0      CCH Pounder   \n",
       "Pirates of the Caribbean: At World's End          563.0      Johnny Depp   \n",
       "Spectre                                             0.0  Christoph Waltz   \n",
       "The Dark Knight Rises                           22000.0        Tom Hardy   \n",
       "Star Wars: Episode VII - The Force Awakens        131.0      Doug Walker   \n",
       "\n",
       "                                            actor1_fb            actor2  \\\n",
       "title                                                                     \n",
       "Avatar                                         1000.0  Joel David Moore   \n",
       "Pirates of the Caribbean: At World's End      40000.0     Orlando Bloom   \n",
       "Spectre                                       11000.0      Rory Kinnear   \n",
       "The Dark Knight Rises                         27000.0    Christian Bale   \n",
       "Star Wars: Episode VII - The Force Awakens      131.0        Rob Walker   \n",
       "\n",
       "                                            actor2_fb                actor3  \\\n",
       "title                                                                         \n",
       "Avatar                                          936.0             Wes Studi   \n",
       "Pirates of the Caribbean: At World's End       5000.0        Jack Davenport   \n",
       "Spectre                                         393.0      Stephanie Sigman   \n",
       "The Dark Knight Rises                         23000.0  Joseph Gordon-Levitt   \n",
       "Star Wars: Episode VII - The Force Awakens       12.0                   NaN   \n",
       "\n",
       "                                            actor3_fb        gross  \\\n",
       "title                                                                \n",
       "Avatar                                          855.0  760505847.0   \n",
       "Pirates of the Caribbean: At World's End       1000.0  309404152.0   \n",
       "Spectre                                         161.0  200074175.0   \n",
       "The Dark Knight Rises                         23000.0  448130642.0   \n",
       "Star Wars: Episode VII - The Force Awakens        NaN          NaN   \n",
       "\n",
       "                                                                     genres  \\\n",
       "title                                                                         \n",
       "Avatar                                      Action|Adventure|Fantasy|Sci-Fi   \n",
       "Pirates of the Caribbean: At World's End           Action|Adventure|Fantasy   \n",
       "Spectre                                           Action|Adventure|Thriller   \n",
       "The Dark Knight Rises                                       Action|Thriller   \n",
       "Star Wars: Episode VII - The Force Awakens                      Documentary   \n",
       "\n",
       "                                            num_reviews  num_voted_users  \\\n",
       "title                                                                      \n",
       "Avatar                                            723.0           886204   \n",
       "Pirates of the Caribbean: At World's End          302.0           471220   \n",
       "Spectre                                           602.0           275868   \n",
       "The Dark Knight Rises                             813.0          1144337   \n",
       "Star Wars: Episode VII - The Force Awakens          NaN                8   \n",
       "\n",
       "                                                                                plot_keywords  \\\n",
       "title                                                                                           \n",
       "Avatar                                                 avatar|future|marine|native|paraplegic   \n",
       "Pirates of the Caribbean: At World's End    goddess|marriage ceremony|marriage proposal|pi...   \n",
       "Spectre                                                   bomb|espionage|sequel|spy|terrorist   \n",
       "The Dark Knight Rises                       deception|imprisonment|lawlessness|police offi...   \n",
       "Star Wars: Episode VII - The Force Awakens                                                NaN   \n",
       "\n",
       "                                           language country       budget  \\\n",
       "title                                                                      \n",
       "Avatar                                      English     USA  237000000.0   \n",
       "Pirates of the Caribbean: At World's End    English     USA  300000000.0   \n",
       "Spectre                                     English      UK  245000000.0   \n",
       "The Dark Knight Rises                       English     USA  250000000.0   \n",
       "Star Wars: Episode VII - The Force Awakens      NaN     NaN          NaN   \n",
       "\n",
       "                                            imdb_score  \n",
       "title                                                   \n",
       "Avatar                                             7.9  \n",
       "Pirates of the Caribbean: At World's End           7.1  \n",
       "Spectre                                            6.8  \n",
       "The Dark Knight Rises                              8.5  \n",
       "Star Wars: Episode VII - The Force Awakens         7.1  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie = pd.read_csv('../data/movie.csv', index_col='title')\n",
    "movie.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "actor 1 has the most FB likes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "actor1_fb    6494.488491\n",
       "actor2_fb    1621.923516\n",
       "actor3_fb     631.276313\n",
       "dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie[['actor1_fb', 'actor2_fb', 'actor3_fb']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "It's also a good idea to assign just the actor FB likes to their own DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "actor1_fb    6494.488491\n",
       "actor2_fb    1621.923516\n",
       "actor3_fb     631.276313\n",
       "dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actors_fb = movie[['actor1_fb', 'actor2_fb', 'actor3_fb']]\n",
    "actors_fb.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "<span  style=\"color:green; font-size:16px\">Calculate the total Facebook likes of all three actors for each movie</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "Avatar                                         2791.0\n",
       "Pirates of the Caribbean: At World's End      46000.0\n",
       "Spectre                                       11554.0\n",
       "The Dark Knight Rises                         73000.0\n",
       "Star Wars: Episode VII - The Force Awakens      143.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actors_fb.sum(axis='columns').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "<span  style=\"color:green; font-size:16px\">What percentage of movies have more than 10,000 total actor FB likes?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2982099267697315"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(actors_fb.sum(axis='columns') > 10000).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "<span  style=\"color:green; font-size:16px\">Find the median gross revenue in millions of dollars for the movies that have more than 10,000 total actor FB likes. Do the same for movies with 10,000 or less total actor FB likes.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.3919155"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criteria = actors_fb.sum(axis='columns') > 10000\n",
    "movie.loc[criteria, 'gross'].median() / 10 ** 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.8157525"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie.loc[~criteria, 'gross'].median() / 10 ** 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "<span  style=\"color:green; font-size:16px\">From Exercise 4, it appears that movies with more than 10,000 total actor FB likes gross 2.5 times as much. This may be due to the fact that newer movies have more actors that are recognized by FB users. Find the median year produced for both groups.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2006.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie.loc[criteria, 'year'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2005.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie.loc[~criteria, 'year'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "<span  style=\"color:green; font-size:16px\">For each movies made in the year 2016, what is the median of the total actor FB likes?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3571.5"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criteria = movie['year'] == 2016\n",
    "cols = ['actor1_fb', 'actor2_fb', 'actor3_fb']\n",
    "movie.loc[criteria, cols].sum(axis='columns').median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "<span  style=\"color:green; font-size:16px\">Write a function that has a single parameter, `year`. Have it return the median of the total actor FB likes for the given year. Test your function with the year 2016 and verify the result with Exercise 6.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_fb_likes(year):\n",
    "    criteria = movie['year'] == year\n",
    "    cols = ['actor1_fb', 'actor2_fb', 'actor3_fb']\n",
    "    return movie.loc[criteria, cols].sum(axis='columns').median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3571.5"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_fb_likes(2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8\n",
    "<span  style=\"color:green; font-size:16px\">Write a loop to print out the year and median total actor FB likes for that year from 1990 to 2016</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1990 2017.0\n",
      "1991 2436.0\n",
      "1992 2147.5\n",
      "1993 2018.0\n",
      "1994 2368.5\n",
      "1995 2612.0\n",
      "1996 2692.5\n",
      "1997 1964.0\n",
      "1998 2482.0\n",
      "1999 2595.0\n",
      "2000 2378.0\n",
      "2001 2424.0\n",
      "2002 2146.0\n",
      "2003 2019.0\n",
      "2004 2298.0\n",
      "2005 2072.0\n",
      "2006 2359.0\n",
      "2007 2002.5\n",
      "2008 2400.0\n",
      "2009 2145.0\n",
      "2010 2411.0\n",
      "2011 2818.5\n",
      "2012 2426.0\n",
      "2013 2420.0\n",
      "2014 2084.0\n",
      "2015 2063.0\n",
      "2016 3571.5\n"
     ]
    }
   ],
   "source": [
    "for year in range(1990, 2017):\n",
    "    print(year, median_fb_likes(year))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9\n",
    "<span  style=\"color:green; font-size:16px\">Using the **college** dataset, find the number of non-missing values in each column and again for each row.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "college = pd.read_csv('../data/college.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "non-missing for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instnm                7535\n",
       "city                  7535\n",
       "stabbr                7535\n",
       "hbcu                  7164\n",
       "menonly               7164\n",
       "womenonly             7164\n",
       "relaffil              7535\n",
       "satvrmid              1185\n",
       "satmtmid              1196\n",
       "distanceonly          7164\n",
       "ugds                  6874\n",
       "ugds_white            6874\n",
       "ugds_black            6874\n",
       "ugds_hisp             6874\n",
       "ugds_asian            6874\n",
       "ugds_aian             6874\n",
       "ugds_nhpi             6874\n",
       "ugds_2mor             6874\n",
       "ugds_nra              6874\n",
       "ugds_unkn             6874\n",
       "pptug_ef              6853\n",
       "curroper              7535\n",
       "pctpell               6849\n",
       "pctfloan              6849\n",
       "ug25abv               6718\n",
       "md_earn_wne_p10       6413\n",
       "grad_debt_mdn_supp    7503\n",
       "dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "non-missing values for the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    27\n",
       "1    27\n",
       "2    25\n",
       "3    27\n",
       "4    27\n",
       "dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college.count(axis='columns').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10\n",
    "<span  style=\"color:green; font-size:16px\">What is the average number of missing values for each row?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.000000\n",
       "1     0.000000\n",
       "2     0.074074\n",
       "3     0.000000\n",
       "4     0.000000\n",
       "5     0.000000\n",
       "6     0.074074\n",
       "7     0.074074\n",
       "8     0.000000\n",
       "9     0.000000\n",
       "10    0.000000\n",
       "11    0.074074\n",
       "12    0.000000\n",
       "13    0.074074\n",
       "14    0.074074\n",
       "dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college.isna().mean(axis='columns').head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11\n",
    "<span  style=\"color:green; font-size:16px\">The `UGDS` column of the college dataset contains the total undergraduate population. What is the least number of colleges it would take to have have a total of more than 5 million students.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7116    151558.0\n",
       "1189    229215.0\n",
       "793     290685.0\n",
       "3711    350605.0\n",
       "3669    408689.0\n",
       "725     460969.0\n",
       "3880    510309.0\n",
       "3765    557250.0\n",
       "5817    602174.0\n",
       "1299    646918.0\n",
       "Name: ugds, dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ugds_cumsum = college['ugds'].sort_values(ascending=False).cumsum()\n",
    "ugds_cumsum.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ugds_cumsum < 5000000).sum() + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes the top 185 colleges (by population) to total more than 5 million students. Let's verify the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "ugds_sort = college['ugds'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4989478.0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ugds_sort.iloc[:184].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5007289.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ugds_sort.iloc[:185].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. DataFrame Methods More"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "college = pd.read_csv('../data/college.csv', index_col='instnm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "<span  style=\"color:green; font-size:16px\">Find the number of missing values for each row.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instnm\n",
       "Alabama A & M University               0\n",
       "University of Alabama at Birmingham    0\n",
       "Amridge University                     2\n",
       "University of Alabama in Huntsville    0\n",
       "Alabama State University               0\n",
       "The University of Alabama              0\n",
       "Central Alabama Community College      2\n",
       "Athens State University                2\n",
       "Auburn University at Montgomery        0\n",
       "Auburn University                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college.isna().sum(axis='columns').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "<span  style=\"color:green; font-size:16px\">What percentage of rows have more than 5 missing values?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09011280690112806"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(college.isna().sum(axis='columns') > 5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "<span  style=\"color:green; font-size:16px\">How many total missing values are there in the entire DataFrame?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24808"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "<span  style=\"color:green; font-size:16px\">Several of the columns contain binary data (are either 0 or 1). Can you identify the names of these columns?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by finding the number of unique values of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city                  2514\n",
       "stabbr                  59\n",
       "hbcu                     2\n",
       "menonly                  2\n",
       "womenonly                2\n",
       "relaffil                 2\n",
       "satvrmid               163\n",
       "satmtmid               167\n",
       "distanceonly             2\n",
       "ugds                  2932\n",
       "ugds_white            4397\n",
       "ugds_black            3242\n",
       "ugds_hisp             2809\n",
       "ugds_asian            1254\n",
       "ugds_aian              601\n",
       "ugds_nhpi              363\n",
       "ugds_2mor              957\n",
       "ugds_nra               920\n",
       "ugds_unkn             1517\n",
       "pptug_ef              3420\n",
       "curroper                 2\n",
       "pctpell               4422\n",
       "pctfloan              4155\n",
       "ug25abv               4285\n",
       "md_earn_wne_p10        598\n",
       "grad_debt_mdn_supp    2038\n",
       "dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_unique = college.nunique()\n",
    "col_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do boolean indexing to select just those that are binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hbcu            2\n",
       "menonly         2\n",
       "womenonly       2\n",
       "relaffil        2\n",
       "distanceonly    2\n",
       "curroper        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_unique[col_unique == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can extract the index to get just the names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hbcu', 'menonly', 'womenonly', 'relaffil', 'distanceonly', 'curroper'], dtype='object')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_unique[col_unique == 2].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "<span  style=\"color:green; font-size:16px\">Read the documentation on the `dropna` method. What is the shape of the returned DataFrame when called with the defaults? Call it again except only drop rows if `UGDS` is missing. What is the shape of this DataFrame?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1171, 26)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college.dropna().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas forces you to use a list with the **`subset`** parameter. This is unfortunately inconsistent behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6874, 26)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college.dropna(subset=['ugds']).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "<span  style=\"color:green; font-size:16px\">Create a new boolean column in the college named 'Verbal Higher' that is True for every college that has a higher verbal than math SAT score. Find the mean of this new column. Why does this number look suspiciously low?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "college['Verbal Higher'] = college['satvrmid'] > college['satmtmid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.048042468480424684"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college['Verbal Higher'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One reason it is so low is that there are mostly missing values for the SAT columns and the comparison operators return False when comparing missing values. Notice that 84% of the values are missing for both SAT columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "satvrmid    0.842734\n",
       "satmtmid    0.841274\n",
       "dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['satvrmid', 'satmtmid']\n",
    "college[cols].isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "<span  style=\"color:green; font-size:16px\">Find the real percentage of schools with higher verbal than math SAT scores.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the rows with missing SAT values first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satvrmid</th>\n",
       "      <th>satmtmid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instnm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alabama A &amp; M University</th>\n",
       "      <td>424.0</td>\n",
       "      <td>420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University of Alabama at Birmingham</th>\n",
       "      <td>570.0</td>\n",
       "      <td>565.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University of Alabama in Huntsville</th>\n",
       "      <td>595.0</td>\n",
       "      <td>590.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alabama State University</th>\n",
       "      <td>425.0</td>\n",
       "      <td>430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The University of Alabama</th>\n",
       "      <td>555.0</td>\n",
       "      <td>565.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     satvrmid  satmtmid\n",
       "instnm                                                 \n",
       "Alabama A & M University                424.0     420.0\n",
       "University of Alabama at Birmingham     570.0     565.0\n",
       "University of Alabama in Huntsville     595.0     590.0\n",
       "Alabama State University                425.0     430.0\n",
       "The University of Alabama               555.0     565.0"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['satvrmid', 'satmtmid']\n",
    "sat = college[cols].dropna()\n",
    "sat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30574324324324326"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sat['satvrmid'] > sat['satmtmid']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can also find all those school with equal scores in both subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08699324324324324"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sat['satvrmid'] == sat['satmtmid']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8\n",
    "<span  style=\"color:green; font-size:16px\">Use the `copy` method to create a new copy of the `college` DataFrame and assign it to variable `college2`. Select all the non-white race columns (`ugds_black` through `ugds_unkn`).  Sum the rows of this DataFrame and assign the result to a variable. Now drop all the non-white race columns from the `college2` DataFrame and assign the result to `college3`. </span>\n",
    "    \n",
    "<span  style=\"color:green; font-size:16px\">Use the `insert` method to insert a new column to the right of the `ugds_white` column of the `college3` DataFrame. Name this column `ugds_nonwhite`.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ugds_black</th>\n",
       "      <th>ugds_hisp</th>\n",
       "      <th>ugds_asian</th>\n",
       "      <th>ugds_aian</th>\n",
       "      <th>ugds_nhpi</th>\n",
       "      <th>ugds_2mor</th>\n",
       "      <th>ugds_nra</th>\n",
       "      <th>ugds_unkn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instnm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alabama A &amp; M University</th>\n",
       "      <td>0.9353</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University of Alabama at Birmingham</th>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.0283</td>\n",
       "      <td>0.0518</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amridge University</th>\n",
       "      <td>0.4192</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University of Alabama in Huntsville</th>\n",
       "      <td>0.1255</td>\n",
       "      <td>0.0382</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>0.0350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alabama State University</th>\n",
       "      <td>0.9208</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0243</td>\n",
       "      <td>0.0137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ugds_black  ugds_hisp  ugds_asian  \\\n",
       "instnm                                                                   \n",
       "Alabama A & M University                 0.9353     0.0055      0.0019   \n",
       "University of Alabama at Birmingham      0.2600     0.0283      0.0518   \n",
       "Amridge University                       0.4192     0.0069      0.0034   \n",
       "University of Alabama in Huntsville      0.1255     0.0382      0.0376   \n",
       "Alabama State University                 0.9208     0.0121      0.0019   \n",
       "\n",
       "                                     ugds_aian  ugds_nhpi  ugds_2mor  \\\n",
       "instnm                                                                 \n",
       "Alabama A & M University                0.0024     0.0019     0.0000   \n",
       "University of Alabama at Birmingham     0.0022     0.0007     0.0368   \n",
       "Amridge University                      0.0000     0.0000     0.0000   \n",
       "University of Alabama in Huntsville     0.0143     0.0002     0.0172   \n",
       "Alabama State University                0.0010     0.0006     0.0098   \n",
       "\n",
       "                                     ugds_nra  ugds_unkn  \n",
       "instnm                                                    \n",
       "Alabama A & M University               0.0059     0.0138  \n",
       "University of Alabama at Birmingham    0.0179     0.0100  \n",
       "Amridge University                     0.0000     0.2715  \n",
       "University of Alabama in Huntsville    0.0332     0.0350  \n",
       "Alabama State University               0.0243     0.0137  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college2 = college.copy()\n",
    "college2_race = college2.loc[:, 'ugds_black':'ugds_unkn']\n",
    "college2_race.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instnm\n",
       "Alabama A & M University               0.9667\n",
       "University of Alabama at Birmingham    0.4077\n",
       "Amridge University                     0.7010\n",
       "University of Alabama in Huntsville    0.3012\n",
       "Alabama State University               0.9842\n",
       "dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_white = college2_race.sum(axis='columns')\n",
    "non_white.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>stabbr</th>\n",
       "      <th>hbcu</th>\n",
       "      <th>menonly</th>\n",
       "      <th>womenonly</th>\n",
       "      <th>relaffil</th>\n",
       "      <th>satvrmid</th>\n",
       "      <th>satmtmid</th>\n",
       "      <th>distanceonly</th>\n",
       "      <th>ugds</th>\n",
       "      <th>ugds_white</th>\n",
       "      <th>pptug_ef</th>\n",
       "      <th>curroper</th>\n",
       "      <th>pctpell</th>\n",
       "      <th>pctfloan</th>\n",
       "      <th>ug25abv</th>\n",
       "      <th>md_earn_wne_p10</th>\n",
       "      <th>grad_debt_mdn_supp</th>\n",
       "      <th>Verbal Higher</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instnm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alabama A &amp; M University</th>\n",
       "      <td>Normal</td>\n",
       "      <td>AL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4206.0</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0656</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7356</td>\n",
       "      <td>0.8284</td>\n",
       "      <td>0.1049</td>\n",
       "      <td>30300</td>\n",
       "      <td>33888</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University of Alabama at Birmingham</th>\n",
       "      <td>Birmingham</td>\n",
       "      <td>AL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11383.0</td>\n",
       "      <td>0.5922</td>\n",
       "      <td>0.2607</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3460</td>\n",
       "      <td>0.5214</td>\n",
       "      <td>0.2422</td>\n",
       "      <td>39700</td>\n",
       "      <td>21941.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           city stabbr  hbcu  menonly  \\\n",
       "instnm                                                                  \n",
       "Alabama A & M University                 Normal     AL   1.0      0.0   \n",
       "University of Alabama at Birmingham  Birmingham     AL   0.0      0.0   \n",
       "\n",
       "                                     womenonly  relaffil  satvrmid  satmtmid  \\\n",
       "instnm                                                                         \n",
       "Alabama A & M University                   0.0         0     424.0     420.0   \n",
       "University of Alabama at Birmingham        0.0         0     570.0     565.0   \n",
       "\n",
       "                                     distanceonly     ugds  ugds_white  \\\n",
       "instnm                                                                   \n",
       "Alabama A & M University                      0.0   4206.0      0.0333   \n",
       "University of Alabama at Birmingham           0.0  11383.0      0.5922   \n",
       "\n",
       "                                     pptug_ef  curroper  pctpell  pctfloan  \\\n",
       "instnm                                                                       \n",
       "Alabama A & M University               0.0656         1   0.7356    0.8284   \n",
       "University of Alabama at Birmingham    0.2607         1   0.3460    0.5214   \n",
       "\n",
       "                                     ug25abv md_earn_wne_p10  \\\n",
       "instnm                                                         \n",
       "Alabama A & M University              0.1049           30300   \n",
       "University of Alabama at Birmingham   0.2422           39700   \n",
       "\n",
       "                                    grad_debt_mdn_supp  Verbal Higher  \n",
       "instnm                                                                 \n",
       "Alabama A & M University                         33888           True  \n",
       "University of Alabama at Birmingham            21941.5           True  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college3 = college2.drop(columns=college2_race.columns)\n",
    "college3.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "college3.insert(11, 'ugds_nonwhite', non_white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>stabbr</th>\n",
       "      <th>hbcu</th>\n",
       "      <th>menonly</th>\n",
       "      <th>womenonly</th>\n",
       "      <th>relaffil</th>\n",
       "      <th>satvrmid</th>\n",
       "      <th>satmtmid</th>\n",
       "      <th>distanceonly</th>\n",
       "      <th>ugds</th>\n",
       "      <th>ugds_white</th>\n",
       "      <th>ugds_nonwhite</th>\n",
       "      <th>pptug_ef</th>\n",
       "      <th>curroper</th>\n",
       "      <th>pctpell</th>\n",
       "      <th>pctfloan</th>\n",
       "      <th>ug25abv</th>\n",
       "      <th>md_earn_wne_p10</th>\n",
       "      <th>grad_debt_mdn_supp</th>\n",
       "      <th>Verbal Higher</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instnm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alabama A &amp; M University</th>\n",
       "      <td>Normal</td>\n",
       "      <td>AL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4206.0</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.9667</td>\n",
       "      <td>0.0656</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7356</td>\n",
       "      <td>0.8284</td>\n",
       "      <td>0.1049</td>\n",
       "      <td>30300</td>\n",
       "      <td>33888</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University of Alabama at Birmingham</th>\n",
       "      <td>Birmingham</td>\n",
       "      <td>AL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11383.0</td>\n",
       "      <td>0.5922</td>\n",
       "      <td>0.4077</td>\n",
       "      <td>0.2607</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3460</td>\n",
       "      <td>0.5214</td>\n",
       "      <td>0.2422</td>\n",
       "      <td>39700</td>\n",
       "      <td>21941.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           city stabbr  hbcu  menonly  \\\n",
       "instnm                                                                  \n",
       "Alabama A & M University                 Normal     AL   1.0      0.0   \n",
       "University of Alabama at Birmingham  Birmingham     AL   0.0      0.0   \n",
       "\n",
       "                                     womenonly  relaffil  satvrmid  satmtmid  \\\n",
       "instnm                                                                         \n",
       "Alabama A & M University                   0.0         0     424.0     420.0   \n",
       "University of Alabama at Birmingham        0.0         0     570.0     565.0   \n",
       "\n",
       "                                     distanceonly     ugds  ugds_white  \\\n",
       "instnm                                                                   \n",
       "Alabama A & M University                      0.0   4206.0      0.0333   \n",
       "University of Alabama at Birmingham           0.0  11383.0      0.5922   \n",
       "\n",
       "                                     ugds_nonwhite  pptug_ef  curroper  \\\n",
       "instnm                                                                   \n",
       "Alabama A & M University                    0.9667    0.0656         1   \n",
       "University of Alabama at Birmingham         0.4077    0.2607         1   \n",
       "\n",
       "                                     pctpell  pctfloan  ug25abv  \\\n",
       "instnm                                                            \n",
       "Alabama A & M University              0.7356    0.8284   0.1049   \n",
       "University of Alabama at Birmingham   0.3460    0.5214   0.2422   \n",
       "\n",
       "                                    md_earn_wne_p10 grad_debt_mdn_supp  \\\n",
       "instnm                                                                   \n",
       "Alabama A & M University                      30300              33888   \n",
       "University of Alabama at Birmingham           39700            21941.5   \n",
       "\n",
       "                                     Verbal Higher  \n",
       "instnm                                              \n",
       "Alabama A & M University                      True  \n",
       "University of Alabama at Birmingham           True  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college3.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>stabbr</th>\n",
       "      <th>hbcu</th>\n",
       "      <th>menonly</th>\n",
       "      <th>womenonly</th>\n",
       "      <th>relaffil</th>\n",
       "      <th>satvrmid</th>\n",
       "      <th>satmtmid</th>\n",
       "      <th>distanceonly</th>\n",
       "      <th>ugds</th>\n",
       "      <th>ugds_white</th>\n",
       "      <th>ugds_nonwhite</th>\n",
       "      <th>pptug_ef</th>\n",
       "      <th>curroper</th>\n",
       "      <th>pctpell</th>\n",
       "      <th>pctfloan</th>\n",
       "      <th>ug25abv</th>\n",
       "      <th>md_earn_wne_p10</th>\n",
       "      <th>grad_debt_mdn_supp</th>\n",
       "      <th>Verbal Higher</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instnm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alabama A &amp; M University</th>\n",
       "      <td>Normal</td>\n",
       "      <td>AL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4206.0</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.9667</td>\n",
       "      <td>0.0656</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7356</td>\n",
       "      <td>0.8284</td>\n",
       "      <td>0.1049</td>\n",
       "      <td>30300</td>\n",
       "      <td>33888</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University of Alabama at Birmingham</th>\n",
       "      <td>Birmingham</td>\n",
       "      <td>AL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11383.0</td>\n",
       "      <td>0.5922</td>\n",
       "      <td>0.4077</td>\n",
       "      <td>0.2607</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3460</td>\n",
       "      <td>0.5214</td>\n",
       "      <td>0.2422</td>\n",
       "      <td>39700</td>\n",
       "      <td>21941.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           city stabbr  hbcu  menonly  \\\n",
       "instnm                                                                  \n",
       "Alabama A & M University                 Normal     AL   1.0      0.0   \n",
       "University of Alabama at Birmingham  Birmingham     AL   0.0      0.0   \n",
       "\n",
       "                                     womenonly  relaffil  satvrmid  satmtmid  \\\n",
       "instnm                                                                         \n",
       "Alabama A & M University                   0.0         0     424.0     420.0   \n",
       "University of Alabama at Birmingham        0.0         0     570.0     565.0   \n",
       "\n",
       "                                     distanceonly     ugds  ugds_white  \\\n",
       "instnm                                                                   \n",
       "Alabama A & M University                      0.0   4206.0      0.0333   \n",
       "University of Alabama at Birmingham           0.0  11383.0      0.5922   \n",
       "\n",
       "                                     ugds_nonwhite  pptug_ef  curroper  \\\n",
       "instnm                                                                   \n",
       "Alabama A & M University                    0.9667    0.0656         1   \n",
       "University of Alabama at Birmingham         0.4077    0.2607         1   \n",
       "\n",
       "                                     pctpell  pctfloan  ug25abv  \\\n",
       "instnm                                                            \n",
       "Alabama A & M University              0.7356    0.8284   0.1049   \n",
       "University of Alabama at Birmingham   0.3460    0.5214   0.2422   \n",
       "\n",
       "                                    md_earn_wne_p10 grad_debt_mdn_supp  \\\n",
       "instnm                                                                   \n",
       "Alabama A & M University                      30300              33888   \n",
       "University of Alabama at Birmingham           39700            21941.5   \n",
       "\n",
       "                                     Verbal Higher  \n",
       "instnm                                              \n",
       "Alabama A & M University                      True  \n",
       "University of Alabama at Birmingham           True  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all in one cell\n",
    "college2 = college.copy()\n",
    "college2_race = college2.loc[:, 'ugds_black':'ugds_unkn']\n",
    "non_white = college2_race.sum(axis='columns')\n",
    "college3 = college2.drop(columns=college2_race.columns)\n",
    "college3.insert(11, 'ugds_nonwhite', non_white)\n",
    "college3.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the flights dataset with the remainder of the Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9\n",
    "<span  style=\"color:green; font-size:16px\">Read in the flights dataset (`flights.csv`) and call `dropna` with the defaults. What kind of DataFrame was returned? Why? Verify that each row has at least one missing value.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = pd.read_csv('../data/flights.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>airline</th>\n",
       "      <th>flight_number</th>\n",
       "      <th>tail_number</th>\n",
       "      <th>origin_airport</th>\n",
       "      <th>destination_airport</th>\n",
       "      <th>scheduled_departure</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>departure_delay</th>\n",
       "      <th>taxi_out</th>\n",
       "      <th>wheels_off</th>\n",
       "      <th>scheduled_time</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>air_time</th>\n",
       "      <th>distance</th>\n",
       "      <th>wheels_on</th>\n",
       "      <th>taxi_in</th>\n",
       "      <th>scheduled_arrival</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>arrival_delay</th>\n",
       "      <th>diverted</th>\n",
       "      <th>cancelled</th>\n",
       "      <th>cancellation_reason</th>\n",
       "      <th>air_system_delay</th>\n",
       "      <th>security_delay</th>\n",
       "      <th>airline_delay</th>\n",
       "      <th>late_aircraft_delay</th>\n",
       "      <th>weather_delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [year, month, day, day_of_week, airline, flight_number, tail_number, origin_airport, destination_airport, scheduled_departure, departure_time, departure_delay, taxi_out, wheels_off, scheduled_time, elapsed_time, air_time, distance, wheels_on, taxi_in, scheduled_arrival, arrival_time, arrival_delay, diverted, cancelled, cancellation_reason, air_system_delay, security_delay, airline_delay, late_aircraft_delay, weather_delay]\n",
       "Index: []"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(flights.isna().sum(axis='columns') > 0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the `all` method to verify that all values in a Series are `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(flights.isna().sum(axis='columns') > 0).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10\n",
    "<span  style=\"color:green; font-size:16px\">Read the `dropna` docs again and keep rows that have at least 28 non-missing values. Verify the results.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11685, 31)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.dropna(thresh=28).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11685"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(flights.notna().sum(axis='columns') >= 28).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11\n",
    "<span  style=\"color:green; font-size:16px\">Find the longest `arrival_delay` for every  airline for every month.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>month</th>\n",
       "      <th>arrival_delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58188</th>\n",
       "      <td>UA</td>\n",
       "      <td>12</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32218</th>\n",
       "      <td>AA</td>\n",
       "      <td>7</td>\n",
       "      <td>858.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>F9</td>\n",
       "      <td>2</td>\n",
       "      <td>839.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37448</th>\n",
       "      <td>DL</td>\n",
       "      <td>8</td>\n",
       "      <td>741.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>AA</td>\n",
       "      <td>1</td>\n",
       "      <td>732.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline  month  arrival_delay\n",
       "58188      UA     12         1185.0\n",
       "32218      AA      7          858.0\n",
       "5540       F9      2          839.0\n",
       "37448      DL      8          741.0\n",
       "179        AA      1          732.0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['airline', 'month', 'arrival_delay']\n",
    "airline_month_delay = flights[cols]\n",
    "airline_month_delay.sort_values('arrival_delay', ascending=False) \\\n",
    "                   .drop_duplicates(subset=['airline', 'month']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. DataFrame Methods More II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>dept</th>\n",
       "      <th>salary</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>hire_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>45279.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2015-02-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENGINEER/OPERATOR</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>63166.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>1982-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SENIOR POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>66614.0</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>1984-11-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENGINEER</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>71680.0</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Male</td>\n",
       "      <td>2012-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CARPENTER</td>\n",
       "      <td>Houston Airport System (HAS)</td>\n",
       "      <td>42390.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2013-11-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   title                            dept   salary   race  \\\n",
       "0         POLICE OFFICER   Houston Police Department-HPD  45279.0  White   \n",
       "1      ENGINEER/OPERATOR   Houston Fire Department (HFD)  63166.0  White   \n",
       "2  SENIOR POLICE OFFICER   Houston Police Department-HPD  66614.0  Black   \n",
       "3               ENGINEER  Public Works & Engineering-PWE  71680.0  Asian   \n",
       "4              CARPENTER    Houston Airport System (HAS)  42390.0  White   \n",
       "\n",
       "  gender   hire_date  \n",
       "0   Male  2015-02-03  \n",
       "1   Male  1982-02-08  \n",
       "2   Male  1984-11-26  \n",
       "3   Male  2012-03-26  \n",
       "4   Male  2013-11-04  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "emp = pd.read_csv('../data/employee.csv')\n",
    "emp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "<span  style=\"color:green; font-size:16px\">How many unique combinations of department and title exist?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "315"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emp.drop_duplicates(subset=['dept', 'title']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "<span  style=\"color:green; font-size:16px\">Since only Series methods have a `unique` method, can you think of a creative way of getting the same result as Exercise 1 with the `unique` method?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          Houston Police Department-HPDPOLICE OFFICER\n",
       "1       Houston Fire Department (HFD)ENGINEER/OPERATOR\n",
       "2    Houston Police Department-HPDSENIOR POLICE OFF...\n",
       "3               Public Works & Engineering-PWEENGINEER\n",
       "4                Houston Airport System (HAS)CARPENTER\n",
       "dtype: object"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate the two columns together to create a Series\n",
    "dept_title = emp['dept'] + emp['title']\n",
    "dept_title.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "315"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, use the `unique` method.\n",
    "len(dept_title.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "315"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in one line\n",
    "len((emp['dept'] + emp['title']).unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "<span  style=\"color:green; font-size:16px\">Find the occurrence of all race and gender combinations. For instance, you would return an object that contains the number of 'Hispanic Males', 'Black Females', etc...</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    White - Male\n",
       "1    White - Male\n",
       "2    Black - Male\n",
       "3    Asian - Male\n",
       "4    White - Male\n",
       "dtype: object"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race_gender = emp['race'] + ' - ' + emp['gender']\n",
    "race_gender.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "White - Male                522\n",
       "Black - Male                326\n",
       "Hispanic - Male             294\n",
       "Black - Female              216\n",
       "Hispanic - Female           101\n",
       "White - Female               78\n",
       "Asian - Male                 70\n",
       "Asian - Female               18\n",
       "Native American - Female      4\n",
       "Native American - Male        4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race_gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "White - Male                0.320\n",
       "Black - Male                0.200\n",
       "Hispanic - Male             0.180\n",
       "Black - Female              0.132\n",
       "Hispanic - Female           0.062\n",
       "White - Female              0.048\n",
       "Asian - Male                0.043\n",
       "Asian - Female              0.011\n",
       "Native American - Female    0.002\n",
       "Native American - Male      0.002\n",
       "dtype: float64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in one line\n",
    "# normalized to get relative frequency\n",
    "(emp['race'] + ' - ' + emp['gender']).value_counts(normalize=True).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "<span  style=\"color:green; font-size:16px\">Find the relative frequency of departments for all employees and then find the relative frequency of departments for the top 100 salaries. Compare the differences.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Houston Police Department-HPD     0.385965\n",
       "Houston Fire Department (HFD)     0.232305\n",
       "Public Works & Engineering-PWE    0.207502\n",
       "Health & Human Services           0.065336\n",
       "Houston Airport System (HAS)      0.064126\n",
       "Parks & Recreation                0.044767\n",
       "Name: dept, dtype: float64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dept_freq = emp['dept'].value_counts(normalize=True)\n",
    "dept_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>dept</th>\n",
       "      <th>salary</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>hire_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>ASSOCIATE EMS PHYSICIAN DIRECTOR,MD</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>210588.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2001-09-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>DEPUTY DIRECTOR-FINANCE &amp; ADMINISTRATION</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>199596.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2007-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>DEPUTY DIRECTOR-AVIATION (EX LVL)</td>\n",
       "      <td>Houston Airport System (HAS)</td>\n",
       "      <td>186192.0</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>2013-08-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CHIEF PHYSICIAN,MD</td>\n",
       "      <td>Health &amp; Human Services</td>\n",
       "      <td>180416.0</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>1987-05-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>DEPUTY DIRECTOR-PUBLIC WORKS (EXECUTIVE</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>178331.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>1991-02-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         title  \\\n",
       "154        ASSOCIATE EMS PHYSICIAN DIRECTOR,MD   \n",
       "630   DEPUTY DIRECTOR-FINANCE & ADMINISTRATION   \n",
       "702          DEPUTY DIRECTOR-AVIATION (EX LVL)   \n",
       "8                           CHIEF PHYSICIAN,MD   \n",
       "1009   DEPUTY DIRECTOR-PUBLIC WORKS (EXECUTIVE   \n",
       "\n",
       "                                dept    salary   race  gender   hire_date  \n",
       "154    Houston Fire Department (HFD)  210588.0  White    Male  2001-09-05  \n",
       "630    Houston Police Department-HPD  199596.0  White    Male  2007-02-01  \n",
       "702     Houston Airport System (HAS)  186192.0  Black    Male  2013-08-22  \n",
       "8            Health & Human Services  180416.0  Black    Male  1987-05-22  \n",
       "1009  Public Works & Engineering-PWE  178331.0  White  Female  1991-02-12  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_top50 = emp.nlargest(100, 'salary')\n",
    "emp_top50.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Public Works & Engineering-PWE    0.31\n",
       "Houston Police Department-HPD     0.22\n",
       "Houston Fire Department (HFD)     0.20\n",
       "Houston Airport System (HAS)      0.17\n",
       "Health & Human Services           0.08\n",
       "Parks & Recreation                0.02\n",
       "Name: dept, dtype: float64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dept_freq_top50 = emp_top50['dept'].value_counts(normalize=True)\n",
    "dept_freq_top50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Health & Human Services           0.014664\n",
       "Houston Airport System (HAS)      0.105874\n",
       "Houston Fire Department (HFD)    -0.032305\n",
       "Houston Police Department-HPD    -0.165965\n",
       "Parks & Recreation               -0.024767\n",
       "Public Works & Engineering-PWE    0.102498\n",
       "Name: dept, dtype: float64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The police dept makes up 38.5% of employees \n",
    "# but only 22% of the top 100 salaries\n",
    "dept_freq_top50 - dept_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "<span  style=\"color:green; font-size:16px\">Create a new column `bonus` right after the salary column equal to 10% of the salary. Round the bonus to the nearest thousand.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>dept</th>\n",
       "      <th>salary</th>\n",
       "      <th>bonus</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>hire_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>45279.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2015-02-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENGINEER/OPERATOR</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>63166.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>1982-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SENIOR POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>66614.0</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>1984-11-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENGINEER</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>71680.0</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Male</td>\n",
       "      <td>2012-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CARPENTER</td>\n",
       "      <td>Houston Airport System (HAS)</td>\n",
       "      <td>42390.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2013-11-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   title                            dept   salary   bonus  \\\n",
       "0         POLICE OFFICER   Houston Police Department-HPD  45279.0  5000.0   \n",
       "1      ENGINEER/OPERATOR   Houston Fire Department (HFD)  63166.0  6000.0   \n",
       "2  SENIOR POLICE OFFICER   Houston Police Department-HPD  66614.0  7000.0   \n",
       "3               ENGINEER  Public Works & Engineering-PWE  71680.0  7000.0   \n",
       "4              CARPENTER    Houston Airport System (HAS)  42390.0  4000.0   \n",
       "\n",
       "    race gender   hire_date  \n",
       "0  White   Male  2015-02-03  \n",
       "1  White   Male  1982-02-08  \n",
       "2  Black   Male  1984-11-26  \n",
       "3  Asian   Male  2012-03-26  \n",
       "4  White   Male  2013-11-04  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bonus = (emp['salary'] * .1).round(-3)\n",
    "emp.insert(3, 'bonus', bonus)\n",
    "emp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the flights dataset for the remaining exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>airline</th>\n",
       "      <th>flight_number</th>\n",
       "      <th>tail_number</th>\n",
       "      <th>origin_airport</th>\n",
       "      <th>destination_airport</th>\n",
       "      <th>scheduled_departure</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>departure_delay</th>\n",
       "      <th>taxi_out</th>\n",
       "      <th>wheels_off</th>\n",
       "      <th>scheduled_time</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>air_time</th>\n",
       "      <th>distance</th>\n",
       "      <th>wheels_on</th>\n",
       "      <th>taxi_in</th>\n",
       "      <th>scheduled_arrival</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>arrival_delay</th>\n",
       "      <th>diverted</th>\n",
       "      <th>cancelled</th>\n",
       "      <th>cancellation_reason</th>\n",
       "      <th>air_system_delay</th>\n",
       "      <th>security_delay</th>\n",
       "      <th>airline_delay</th>\n",
       "      <th>late_aircraft_delay</th>\n",
       "      <th>weather_delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>WN</td>\n",
       "      <td>1908</td>\n",
       "      <td>N8324A</td>\n",
       "      <td>LAX</td>\n",
       "      <td>SLC</td>\n",
       "      <td>1625</td>\n",
       "      <td>1723.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1733.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>590</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1905</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>UA</td>\n",
       "      <td>581</td>\n",
       "      <td>N448UA</td>\n",
       "      <td>DEN</td>\n",
       "      <td>IAD</td>\n",
       "      <td>823</td>\n",
       "      <td>830.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>841.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1452</td>\n",
       "      <td>1315.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1333</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>MQ</td>\n",
       "      <td>2851</td>\n",
       "      <td>N645MQ</td>\n",
       "      <td>DFW</td>\n",
       "      <td>VPS</td>\n",
       "      <td>1305</td>\n",
       "      <td>1341.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1359.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>641</td>\n",
       "      <td>1524.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1453</td>\n",
       "      <td>1528.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>383</td>\n",
       "      <td>N3EUAA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>DCA</td>\n",
       "      <td>1555</td>\n",
       "      <td>1602.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1615.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1192</td>\n",
       "      <td>1921.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1935</td>\n",
       "      <td>1928.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>WN</td>\n",
       "      <td>3047</td>\n",
       "      <td>N560WN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1720</td>\n",
       "      <td>1808.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1814.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1363</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2225</td>\n",
       "      <td>2304.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  day_of_week airline  flight_number tail_number  \\\n",
       "0  2015      1    1            4      WN           1908      N8324A   \n",
       "1  2015      1    1            4      UA            581      N448UA   \n",
       "2  2015      1    1            4      MQ           2851      N645MQ   \n",
       "3  2015      1    1            4      AA            383      N3EUAA   \n",
       "4  2015      1    1            4      WN           3047      N560WN   \n",
       "\n",
       "  origin_airport destination_airport  scheduled_departure  departure_time  \\\n",
       "0            LAX                 SLC                 1625          1723.0   \n",
       "1            DEN                 IAD                  823           830.0   \n",
       "2            DFW                 VPS                 1305          1341.0   \n",
       "3            DFW                 DCA                 1555          1602.0   \n",
       "4            LAX                 MCI                 1720          1808.0   \n",
       "\n",
       "   departure_delay  taxi_out  wheels_off  scheduled_time  elapsed_time  \\\n",
       "0             58.0      10.0      1733.0           100.0         107.0   \n",
       "1              7.0      11.0       841.0           190.0         170.0   \n",
       "2             36.0      18.0      1359.0           108.0         107.0   \n",
       "3              7.0      13.0      1615.0           160.0         146.0   \n",
       "4             48.0       6.0      1814.0           185.0         176.0   \n",
       "\n",
       "   air_time  distance  wheels_on  taxi_in  scheduled_arrival  arrival_time  \\\n",
       "0      94.0       590     2007.0      3.0               1905        2010.0   \n",
       "1     154.0      1452     1315.0      5.0               1333        1320.0   \n",
       "2      85.0       641     1524.0      4.0               1453        1528.0   \n",
       "3     126.0      1192     1921.0      7.0               1935        1928.0   \n",
       "4     166.0      1363     2300.0      4.0               2225        2304.0   \n",
       "\n",
       "   arrival_delay  diverted  cancelled cancellation_reason  air_system_delay  \\\n",
       "0           65.0         0          0                 NaN              31.0   \n",
       "1          -13.0         0          0                 NaN               NaN   \n",
       "2           35.0         0          0                 NaN               0.0   \n",
       "3           -7.0         0          0                 NaN               NaN   \n",
       "4           39.0         0          0                 NaN               0.0   \n",
       "\n",
       "   security_delay  airline_delay  late_aircraft_delay  weather_delay  \n",
       "0             0.0            0.0                 34.0            0.0  \n",
       "1             NaN            NaN                  NaN            NaN  \n",
       "2             0.0           35.0                  0.0            0.0  \n",
       "3             NaN            NaN                  NaN            NaN  \n",
       "4             0.0           17.0                 22.0            0.0  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights = pd.read_csv('../data/flights.csv')\n",
    "pd.set_option('display.max_columns', 40)\n",
    "flights.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "<span  style=\"color:green; font-size:16px\">Find the five variables with the highest correlation to `departure_delay`.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>flight_number</th>\n",
       "      <th>scheduled_departure</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>departure_delay</th>\n",
       "      <th>taxi_out</th>\n",
       "      <th>wheels_off</th>\n",
       "      <th>scheduled_time</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>air_time</th>\n",
       "      <th>distance</th>\n",
       "      <th>wheels_on</th>\n",
       "      <th>taxi_in</th>\n",
       "      <th>scheduled_arrival</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>arrival_delay</th>\n",
       "      <th>diverted</th>\n",
       "      <th>cancelled</th>\n",
       "      <th>air_system_delay</th>\n",
       "      <th>security_delay</th>\n",
       "      <th>airline_delay</th>\n",
       "      <th>late_aircraft_delay</th>\n",
       "      <th>weather_delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>departure_delay</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.010273</td>\n",
       "      <td>-0.001296</td>\n",
       "      <td>-0.010867</td>\n",
       "      <td>-0.021415</td>\n",
       "      <td>0.097870</td>\n",
       "      <td>0.143027</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.056017</td>\n",
       "      <td>0.130511</td>\n",
       "      <td>0.030539</td>\n",
       "      <td>0.032522</td>\n",
       "      <td>0.025231</td>\n",
       "      <td>0.028029</td>\n",
       "      <td>-0.013130</td>\n",
       "      <td>0.017020</td>\n",
       "      <td>0.078079</td>\n",
       "      <td>-0.023133</td>\n",
       "      <td>0.943079</td>\n",
       "      <td>0.014899</td>\n",
       "      <td>0.035749</td>\n",
       "      <td>0.043227</td>\n",
       "      <td>0.005982</td>\n",
       "      <td>0.566649</td>\n",
       "      <td>0.614744</td>\n",
       "      <td>0.262567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrival_delay</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.028120</td>\n",
       "      <td>-0.002729</td>\n",
       "      <td>-0.017629</td>\n",
       "      <td>0.010516</td>\n",
       "      <td>0.087381</td>\n",
       "      <td>0.131118</td>\n",
       "      <td>0.943079</td>\n",
       "      <td>0.260143</td>\n",
       "      <td>0.124291</td>\n",
       "      <td>-0.018146</td>\n",
       "      <td>0.042080</td>\n",
       "      <td>0.002777</td>\n",
       "      <td>-0.013538</td>\n",
       "      <td>-0.007764</td>\n",
       "      <td>0.120074</td>\n",
       "      <td>0.073389</td>\n",
       "      <td>-0.017111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.226909</td>\n",
       "      <td>0.005134</td>\n",
       "      <td>0.546762</td>\n",
       "      <td>0.580354</td>\n",
       "      <td>0.290796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>late_aircraft_delay</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.021249</td>\n",
       "      <td>0.022794</td>\n",
       "      <td>-0.001918</td>\n",
       "      <td>-0.011046</td>\n",
       "      <td>0.110426</td>\n",
       "      <td>0.146448</td>\n",
       "      <td>0.614744</td>\n",
       "      <td>-0.112953</td>\n",
       "      <td>0.114102</td>\n",
       "      <td>-0.024267</td>\n",
       "      <td>-0.071855</td>\n",
       "      <td>-0.044821</td>\n",
       "      <td>-0.024944</td>\n",
       "      <td>-0.089945</td>\n",
       "      <td>-0.064373</td>\n",
       "      <td>0.064146</td>\n",
       "      <td>-0.093422</td>\n",
       "      <td>0.580354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.149016</td>\n",
       "      <td>-0.013208</td>\n",
       "      <td>-0.098662</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.010634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airline_delay</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009286</td>\n",
       "      <td>-0.004480</td>\n",
       "      <td>0.020719</td>\n",
       "      <td>0.017408</td>\n",
       "      <td>-0.053221</td>\n",
       "      <td>-0.013018</td>\n",
       "      <td>0.566649</td>\n",
       "      <td>-0.097181</td>\n",
       "      <td>-0.019120</td>\n",
       "      <td>0.031116</td>\n",
       "      <td>-0.005039</td>\n",
       "      <td>0.019421</td>\n",
       "      <td>0.027969</td>\n",
       "      <td>-0.055553</td>\n",
       "      <td>-0.049251</td>\n",
       "      <td>-0.042364</td>\n",
       "      <td>-0.051545</td>\n",
       "      <td>0.546762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.143580</td>\n",
       "      <td>-0.016622</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.098662</td>\n",
       "      <td>-0.069291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_delay</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.007908</td>\n",
       "      <td>0.029583</td>\n",
       "      <td>-0.039281</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.004495</td>\n",
       "      <td>-0.001466</td>\n",
       "      <td>0.262567</td>\n",
       "      <td>0.090456</td>\n",
       "      <td>-0.001796</td>\n",
       "      <td>-0.017605</td>\n",
       "      <td>-0.004823</td>\n",
       "      <td>-0.021089</td>\n",
       "      <td>-0.026772</td>\n",
       "      <td>-0.013280</td>\n",
       "      <td>-0.012330</td>\n",
       "      <td>0.011679</td>\n",
       "      <td>-0.020969</td>\n",
       "      <td>0.290796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008947</td>\n",
       "      <td>-0.005692</td>\n",
       "      <td>-0.069291</td>\n",
       "      <td>-0.010634</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>departure_time</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000306</td>\n",
       "      <td>-0.005033</td>\n",
       "      <td>-0.000223</td>\n",
       "      <td>0.042582</td>\n",
       "      <td>0.946729</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.143027</td>\n",
       "      <td>0.003458</td>\n",
       "      <td>0.959245</td>\n",
       "      <td>-0.098917</td>\n",
       "      <td>-0.100574</td>\n",
       "      <td>-0.099027</td>\n",
       "      <td>-0.099844</td>\n",
       "      <td>0.534003</td>\n",
       "      <td>-0.058068</td>\n",
       "      <td>0.583442</td>\n",
       "      <td>0.501935</td>\n",
       "      <td>0.131118</td>\n",
       "      <td>-0.003364</td>\n",
       "      <td>0.011816</td>\n",
       "      <td>-0.069894</td>\n",
       "      <td>-0.017410</td>\n",
       "      <td>-0.013018</td>\n",
       "      <td>0.146448</td>\n",
       "      <td>-0.001466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     year     month       day  day_of_week  flight_number  \\\n",
       "departure_delay       NaN -0.010273 -0.001296    -0.010867      -0.021415   \n",
       "arrival_delay         NaN -0.028120 -0.002729    -0.017629       0.010516   \n",
       "late_aircraft_delay   NaN  0.021249  0.022794    -0.001918      -0.011046   \n",
       "airline_delay         NaN  0.009286 -0.004480     0.020719       0.017408   \n",
       "weather_delay         NaN -0.007908  0.029583    -0.039281       0.000365   \n",
       "departure_time        NaN -0.000306 -0.005033    -0.000223       0.042582   \n",
       "\n",
       "                     scheduled_departure  departure_time  departure_delay  \\\n",
       "departure_delay                 0.097870        0.143027         1.000000   \n",
       "arrival_delay                   0.087381        0.131118         0.943079   \n",
       "late_aircraft_delay             0.110426        0.146448         0.614744   \n",
       "airline_delay                  -0.053221       -0.013018         0.566649   \n",
       "weather_delay                   0.004495       -0.001466         0.262567   \n",
       "departure_time                  0.946729        1.000000         0.143027   \n",
       "\n",
       "                     taxi_out  wheels_off  scheduled_time  elapsed_time  \\\n",
       "departure_delay      0.056017    0.130511        0.030539      0.032522   \n",
       "arrival_delay        0.260143    0.124291       -0.018146      0.042080   \n",
       "late_aircraft_delay -0.112953    0.114102       -0.024267     -0.071855   \n",
       "airline_delay       -0.097181   -0.019120        0.031116     -0.005039   \n",
       "weather_delay        0.090456   -0.001796       -0.017605     -0.004823   \n",
       "departure_time       0.003458    0.959245       -0.098917     -0.100574   \n",
       "\n",
       "                     air_time  distance  wheels_on   taxi_in  \\\n",
       "departure_delay      0.025231  0.028029  -0.013130  0.017020   \n",
       "arrival_delay        0.002777 -0.013538  -0.007764  0.120074   \n",
       "late_aircraft_delay -0.044821 -0.024944  -0.089945 -0.064373   \n",
       "airline_delay        0.019421  0.027969  -0.055553 -0.049251   \n",
       "weather_delay       -0.021089 -0.026772  -0.013280 -0.012330   \n",
       "departure_time      -0.099027 -0.099844   0.534003 -0.058068   \n",
       "\n",
       "                     scheduled_arrival  arrival_time  arrival_delay  diverted  \\\n",
       "departure_delay               0.078079     -0.023133       0.943079  0.014899   \n",
       "arrival_delay                 0.073389     -0.017111       1.000000       NaN   \n",
       "late_aircraft_delay           0.064146     -0.093422       0.580354       NaN   \n",
       "airline_delay                -0.042364     -0.051545       0.546762       NaN   \n",
       "weather_delay                 0.011679     -0.020969       0.290796       NaN   \n",
       "departure_time                0.583442      0.501935       0.131118 -0.003364   \n",
       "\n",
       "                     cancelled  air_system_delay  security_delay  \\\n",
       "departure_delay       0.035749          0.043227        0.005982   \n",
       "arrival_delay              NaN          0.226909        0.005134   \n",
       "late_aircraft_delay        NaN         -0.149016       -0.013208   \n",
       "airline_delay              NaN         -0.143580       -0.016622   \n",
       "weather_delay              NaN          0.008947       -0.005692   \n",
       "departure_time        0.011816         -0.069894       -0.017410   \n",
       "\n",
       "                     airline_delay  late_aircraft_delay  weather_delay  \n",
       "departure_delay           0.566649             0.614744       0.262567  \n",
       "arrival_delay             0.546762             0.580354       0.290796  \n",
       "late_aircraft_delay      -0.098662             1.000000      -0.010634  \n",
       "airline_delay             1.000000            -0.098662      -0.069291  \n",
       "weather_delay            -0.069291            -0.010634       1.000000  \n",
       "departure_time           -0.013018             0.146448      -0.001466  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.corr().nlargest(6, 'departure_delay')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "\n",
    "<span  style=\"color:green; font-size:16px\">Replace the exact string 'LAX' with 'Los Angeles Airport', 'IAH' with 'George Bush Airport', 'SLC' with 'Salt Lake City Airport', and 'UA' with 'United Airlines'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>airline</th>\n",
       "      <th>flight_number</th>\n",
       "      <th>tail_number</th>\n",
       "      <th>origin_airport</th>\n",
       "      <th>destination_airport</th>\n",
       "      <th>scheduled_departure</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>departure_delay</th>\n",
       "      <th>taxi_out</th>\n",
       "      <th>wheels_off</th>\n",
       "      <th>scheduled_time</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>air_time</th>\n",
       "      <th>distance</th>\n",
       "      <th>wheels_on</th>\n",
       "      <th>taxi_in</th>\n",
       "      <th>scheduled_arrival</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>arrival_delay</th>\n",
       "      <th>diverted</th>\n",
       "      <th>cancelled</th>\n",
       "      <th>cancellation_reason</th>\n",
       "      <th>air_system_delay</th>\n",
       "      <th>security_delay</th>\n",
       "      <th>airline_delay</th>\n",
       "      <th>late_aircraft_delay</th>\n",
       "      <th>weather_delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>WN</td>\n",
       "      <td>1908</td>\n",
       "      <td>N8324A</td>\n",
       "      <td>Los Angeles Airport</td>\n",
       "      <td>Salt Lake City Airport</td>\n",
       "      <td>1625</td>\n",
       "      <td>1723.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1733.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>590</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1905</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>United Airlines</td>\n",
       "      <td>581</td>\n",
       "      <td>N448UA</td>\n",
       "      <td>DEN</td>\n",
       "      <td>IAD</td>\n",
       "      <td>823</td>\n",
       "      <td>830.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>841.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1452</td>\n",
       "      <td>1315.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1333</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>MQ</td>\n",
       "      <td>2851</td>\n",
       "      <td>N645MQ</td>\n",
       "      <td>DFW</td>\n",
       "      <td>VPS</td>\n",
       "      <td>1305</td>\n",
       "      <td>1341.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1359.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>641</td>\n",
       "      <td>1524.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1453</td>\n",
       "      <td>1528.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>383</td>\n",
       "      <td>N3EUAA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>DCA</td>\n",
       "      <td>1555</td>\n",
       "      <td>1602.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1615.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1192</td>\n",
       "      <td>1921.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1935</td>\n",
       "      <td>1928.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>WN</td>\n",
       "      <td>3047</td>\n",
       "      <td>N560WN</td>\n",
       "      <td>Los Angeles Airport</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1720</td>\n",
       "      <td>1808.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1814.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1363</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2225</td>\n",
       "      <td>2304.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>United Airlines</td>\n",
       "      <td>225</td>\n",
       "      <td>N447UA</td>\n",
       "      <td>George Bush Airport</td>\n",
       "      <td>SAN</td>\n",
       "      <td>1450</td>\n",
       "      <td>1451.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1506.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>1303</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1620</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>975</td>\n",
       "      <td>N559AA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>MSY</td>\n",
       "      <td>1250</td>\n",
       "      <td>1414.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1427.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>447</td>\n",
       "      <td>1531.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1410</td>\n",
       "      <td>1533.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>F9</td>\n",
       "      <td>1054</td>\n",
       "      <td>N933FR</td>\n",
       "      <td>SFO</td>\n",
       "      <td>PHX</td>\n",
       "      <td>1020</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>651</td>\n",
       "      <td>1302.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1315</td>\n",
       "      <td>1309.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  day_of_week          airline  flight_number tail_number  \\\n",
       "0  2015      1    1            4               WN           1908      N8324A   \n",
       "1  2015      1    1            4  United Airlines            581      N448UA   \n",
       "2  2015      1    1            4               MQ           2851      N645MQ   \n",
       "3  2015      1    1            4               AA            383      N3EUAA   \n",
       "4  2015      1    1            4               WN           3047      N560WN   \n",
       "5  2015      1    1            4  United Airlines            225      N447UA   \n",
       "6  2015      1    1            4               AA            975      N559AA   \n",
       "7  2015      1    1            4               F9           1054      N933FR   \n",
       "\n",
       "        origin_airport     destination_airport  scheduled_departure  \\\n",
       "0  Los Angeles Airport  Salt Lake City Airport                 1625   \n",
       "1                  DEN                     IAD                  823   \n",
       "2                  DFW                     VPS                 1305   \n",
       "3                  DFW                     DCA                 1555   \n",
       "4  Los Angeles Airport                     MCI                 1720   \n",
       "5  George Bush Airport                     SAN                 1450   \n",
       "6                  DFW                     MSY                 1250   \n",
       "7                  SFO                     PHX                 1020   \n",
       "\n",
       "   departure_time  departure_delay  taxi_out  wheels_off  scheduled_time  \\\n",
       "0          1723.0             58.0      10.0      1733.0           100.0   \n",
       "1           830.0              7.0      11.0       841.0           190.0   \n",
       "2          1341.0             36.0      18.0      1359.0           108.0   \n",
       "3          1602.0              7.0      13.0      1615.0           160.0   \n",
       "4          1808.0             48.0       6.0      1814.0           185.0   \n",
       "5          1451.0              1.0      15.0      1506.0           210.0   \n",
       "6          1414.0             84.0      13.0      1427.0            80.0   \n",
       "7          1013.0             -7.0      18.0      1031.0           115.0   \n",
       "\n",
       "   elapsed_time  air_time  distance  wheels_on  taxi_in  scheduled_arrival  \\\n",
       "0         107.0      94.0       590     2007.0      3.0               1905   \n",
       "1         170.0     154.0      1452     1315.0      5.0               1333   \n",
       "2         107.0      85.0       641     1524.0      4.0               1453   \n",
       "3         146.0     126.0      1192     1921.0      7.0               1935   \n",
       "4         176.0     166.0      1363     2300.0      4.0               2225   \n",
       "5         195.0     178.0      1303     1604.0      2.0               1620   \n",
       "6          79.0      64.0       447     1531.0      2.0               1410   \n",
       "7         116.0      91.0       651     1302.0      7.0               1315   \n",
       "\n",
       "   arrival_time  arrival_delay  diverted  cancelled cancellation_reason  \\\n",
       "0        2010.0           65.0         0          0                 NaN   \n",
       "1        1320.0          -13.0         0          0                 NaN   \n",
       "2        1528.0           35.0         0          0                 NaN   \n",
       "3        1928.0           -7.0         0          0                 NaN   \n",
       "4        2304.0           39.0         0          0                 NaN   \n",
       "5        1606.0          -14.0         0          0                 NaN   \n",
       "6        1533.0           83.0         0          0                 NaN   \n",
       "7        1309.0           -6.0         0          0                 NaN   \n",
       "\n",
       "   air_system_delay  security_delay  airline_delay  late_aircraft_delay  \\\n",
       "0              31.0             0.0            0.0                 34.0   \n",
       "1               NaN             NaN            NaN                  NaN   \n",
       "2               0.0             0.0           35.0                  0.0   \n",
       "3               NaN             NaN            NaN                  NaN   \n",
       "4               0.0             0.0           17.0                 22.0   \n",
       "5               NaN             NaN            NaN                  NaN   \n",
       "6               0.0             0.0            0.0                 83.0   \n",
       "7               NaN             NaN            NaN                  NaN   \n",
       "\n",
       "   weather_delay  \n",
       "0            0.0  \n",
       "1            NaN  \n",
       "2            0.0  \n",
       "3            NaN  \n",
       "4            0.0  \n",
       "5            NaN  \n",
       "6            0.0  \n",
       "7            NaN  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace = {'LAX': 'Los Angeles Airport',\n",
    "           'IAH': 'George Bush Airport',\n",
    "           'UA': 'United Airlines',\n",
    "           'SLC': 'Salt Lake City Airport'}\n",
    "flights.replace(replace).head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8\n",
    "\n",
    "<span  style=\"color:green; font-size:16px\">Find the largest departure delay for every airline. Return just these two columns.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>departure_delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32218</th>\n",
       "      <td>AA</td>\n",
       "      <td>835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8007</th>\n",
       "      <td>AS</td>\n",
       "      <td>338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32918</th>\n",
       "      <td>B6</td>\n",
       "      <td>348.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37448</th>\n",
       "      <td>DL</td>\n",
       "      <td>755.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18459</th>\n",
       "      <td>EV</td>\n",
       "      <td>672.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>F9</td>\n",
       "      <td>852.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49971</th>\n",
       "      <td>HA</td>\n",
       "      <td>298.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29134</th>\n",
       "      <td>MQ</td>\n",
       "      <td>342.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25433</th>\n",
       "      <td>NK</td>\n",
       "      <td>461.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42654</th>\n",
       "      <td>OO</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58188</th>\n",
       "      <td>UA</td>\n",
       "      <td>1194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25455</th>\n",
       "      <td>US</td>\n",
       "      <td>439.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9718</th>\n",
       "      <td>VX</td>\n",
       "      <td>253.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56837</th>\n",
       "      <td>WN</td>\n",
       "      <td>476.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline  departure_delay\n",
       "32218      AA            835.0\n",
       "8007       AS            338.0\n",
       "32918      B6            348.0\n",
       "37448      DL            755.0\n",
       "18459      EV            672.0\n",
       "5540       F9            852.0\n",
       "49971      HA            298.0\n",
       "29134      MQ            342.0\n",
       "25433      NK            461.0\n",
       "42654      OO            735.0\n",
       "58188      UA           1194.0\n",
       "25455      US            439.0\n",
       "9718       VX            253.0\n",
       "56837      WN            476.0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['airline', 'departure_delay']\n",
    "flights_dd = flights[cols]\n",
    "flights_dd.sort_values(cols, ascending=[True, False]) \\\n",
    "          .drop_duplicates(subset='airline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Changing Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "<span  style=\"color:green; font-size:16px\">Find the maximum integer of a 16-bit integer. Then verify it with numpys `iinfo` function.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32767"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 ** 15 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iinfo(min=-32768, max=32767, dtype=int16)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.iinfo('int16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "<span  style=\"color:green; font-size:16px\">Read in the bikes data and select the `trip_duration` column. Find its data type and then use the `memory_usage` method to find how much memory (in bytes) it is using. Change its data type to the smallest possible type so that no information is lost. What percentage of memory has been saved?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     993\n",
       "1     623\n",
       "2    1040\n",
       "3     667\n",
       "4     130\n",
       "Name: tripduration, dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes = pd.read_csv('../data/bikes.csv')\n",
    "td = bikes['tripduration']\n",
    "td.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400792"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td.memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the min and max values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "min       60\n",
       "max    86188\n",
       "Name: tripduration, dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td.agg(['min', 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately a uint16 doesn't quite have enough memory to fit the max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iinfo(min=0, max=65535, dtype=uint16)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.iinfo('uint16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to use 32 bits. Although you can use uint32 its probably best to stick with int32 as this is much more common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iinfo(min=-2147483648, max=2147483647, dtype=int32)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.iinfo('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     993\n",
       "1     623\n",
       "2    1040\n",
       "3     667\n",
       "4     130\n",
       "Name: tripduration, dtype: int32"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td_32 = td.astype('int32')\n",
    "td_32.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200436"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td_32.memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We went from using 64 bits for every value to 32 bits. This should yield a decrease of 50% and we verify this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000998023912653"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td_32.memory_usage() / td.memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "<span  style=\"color:green; font-size:16px\">Use the `randint` function from the numpy `random` module to create 1000 random integers between 1 and 10. Then use this array to create two Series. Name the first `s1` and create it as an 8-bit integer. Name the second `s2` and create it with data type of object. Find the memory used by each Series. Is there a difference?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(1, 10, 1000)\n",
    "s1 = pd.Series(a)\n",
    "s2 = pd.Series(a, dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8080"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8080"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2.memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "<span  style=\"color:green; font-size:16px\">Exercise 3 gave us an incorrect result. The `memory_usage` method doesn't work correctly by default for object data types. You must set the parameter `deep` to `True`. Also, set the `index` parameter to `False` as we are interested in comparing the memory of the values. How many bytes is each value for the different Series?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.memory_usage(index=False, deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36000"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2.memory_usage(index=False, deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Series with data type int64 uses 8 bytes per value while the object data type uses 36 bytes per value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "<span  style=\"color:green; font-size:16px\">The object Series from exercises 3 and 4 contains regular Python integers. Use the `getsizeof` function from the `sys` module to find the amount of memory of the Python integer 1.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that there must be an additional overhead of 8 bytes for each value when creating a numpy array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "<span  style=\"color:green; font-size:16px\">Create three different Series with integer data types. Make them have a different number of items. Make a fourth Series that has these three Series as the values. Output the fourth Series. Can you make sense of it?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                           0    1\n",
       "1    2\n",
       "dtype: int64\n",
       "1      0    4.300\n",
       "1    2.100\n",
       "2    1.554\n",
       "dtype: float64\n",
       "2    0    python\n",
       "1    pandas\n",
       "2     numpy\n",
       "dtype: object\n",
       "dtype: object"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = pd.Series([1, 2])\n",
    "s2 = pd.Series([4.3, 2.1, 1.554])\n",
    "s3 = pd.Series(['python', 'pandas', 'numpy'])\n",
    "s4 = pd.Series([s1, s2, s3])\n",
    "s4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's very hard to decipher what is going on. Series objects are not designed to contain other Series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "<span  style=\"color:green; font-size:16px\">What month is it 1 million minutes after the unix epoch?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   1971-11-26 10:40:00\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([1000000]).astype('datetime64[m]')\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    November\n",
       "dtype: object"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.dt.month_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the time series part, you will learn how to do this in a more direct manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'November'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Timestamp(1000000, unit='m').month_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8\n",
    "<span  style=\"color:green; font-size:16px\">Convert the following Series to float.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1.9\n",
       "1        43\n",
       "2    python\n",
       "dtype: object"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(['1.9', '43', 'python'])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1.9\n",
       "1    43.0\n",
       "2     NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_numeric(s, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9\n",
    "<span  style=\"color:green; font-size:16px\">Take a look at the `dpcapacity_start` column from the bikes dataset. It contains the capacity of the bike rack when the ride began. This number should be an integer but it is a float. Why do you think pandas read this in as a float? Do something to the DataFrame as a whole so that you can convert just this column to an integer. Choose the lowest size integer that is possible.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11.0\n",
       "1    31.0\n",
       "2    15.0\n",
       "3    19.0\n",
       "4    19.0\n",
       "Name: dpcapacity_start, dtype: float64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes['dpcapacity_start'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There must be missing values since integers do not contain them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes['dpcapacity_start'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values easily fit within a 8-bit integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "min     0.0\n",
       "max    55.0\n",
       "Name: dpcapacity_start, dtype: float64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes['dpcapacity_start'].agg(['min', 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop the missing values just for that column and then convert it to an `int8`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11\n",
       "1    31\n",
       "2    15\n",
       "3    19\n",
       "4    19\n",
       "Name: dpcapacity_start, dtype: int8"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes2 = bikes.dropna(subset=['dpcapacity_start']) \\\n",
    "              .astype({'dpcapacity_start': 'int8'})\n",
    "bikes2['dpcapacity_start'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10\n",
    "<span  style=\"color:green; font-size:16px\">pandas recently provided a brand new **nullable integer** data type. It is only available in pandas and not in numpy. You can use it for columns consisting of integers and missing values. You can reference it similarly as the regular integer but with a capital I. For instance, the string `'Int64'` refers to the nullable integer data type with 64 bits. Without dropping values, convert the dpcapacity_start column to a nullable integer with the lowest possible bit size.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11\n",
       "1    31\n",
       "2    15\n",
       "3    19\n",
       "4    19\n",
       "Name: dpcapacity_start, dtype: Int8"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes_na = bikes.astype({'dpcapacity_start': 'Int8'})\n",
    "bikes_na['dpcapacity_start'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this DataFrame has all the rows as the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50089, 50083, 50089)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bikes), len(bikes2), len(bikes_na)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Assigning Subsets of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the bikes dataset for all of the following exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "bikes = pd.read_csv('../data/bikes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "<span  style=\"color:green; font-size:16px\">Change the values of `events` to 'HEAT WAVE' for all rides where `temperature` is above 95. Verify this by outputting just the `events` and `temperature` columns that meet the condition.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>96.1</td>\n",
       "      <td>HEAT WAVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>96.1</td>\n",
       "      <td>HEAT WAVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>96.1</td>\n",
       "      <td>HEAT WAVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     temperature     events\n",
       "395         96.1  HEAT WAVE\n",
       "396         96.1  HEAT WAVE\n",
       "397         96.1  HEAT WAVE"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt = bikes['temperature'] > 95\n",
    "bikes.loc[filt, 'events'] = 'HEAT WAVE'\n",
    "bikes.loc[filt, ['temperature', 'events']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "<span  style=\"color:green; font-size:16px\">Increase the trip duration by 50% for all the rides that took place with a wind speed above 40. Output just the trip duration and wind speed before and after the assignment.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripduration</th>\n",
       "      <th>wind_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22306</th>\n",
       "      <td>130</td>\n",
       "      <td>42.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22307</th>\n",
       "      <td>528</td>\n",
       "      <td>42.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22308</th>\n",
       "      <td>358</td>\n",
       "      <td>42.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22309</th>\n",
       "      <td>221</td>\n",
       "      <td>41.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tripduration  wind_speed\n",
       "22306           130        42.6\n",
       "22307           528        42.6\n",
       "22308           358        42.6\n",
       "22309           221        41.4"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt = bikes['wind_speed'] > 40\n",
    "cols = ['tripduration', 'wind_speed']\n",
    "bikes.loc[filt, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripduration</th>\n",
       "      <th>wind_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22306</th>\n",
       "      <td>195.0</td>\n",
       "      <td>42.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22307</th>\n",
       "      <td>792.0</td>\n",
       "      <td>42.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22308</th>\n",
       "      <td>537.0</td>\n",
       "      <td>42.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22309</th>\n",
       "      <td>331.5</td>\n",
       "      <td>41.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tripduration  wind_speed\n",
       "22306         195.0        42.6\n",
       "22307         792.0        42.6\n",
       "22308         537.0        42.6\n",
       "22309         331.5        41.4"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.loc[filt, 'tripduration'] *= 1.5\n",
    "bikes.loc[filt, cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "<span  style=\"color:green; font-size:16px\">Change the trip duration for the first two rows to 0.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>usertype</th>\n",
       "      <th>gender</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>tripduration</th>\n",
       "      <th>from_station_name</th>\n",
       "      <th>latitude_start</th>\n",
       "      <th>longitude_start</th>\n",
       "      <th>dpcapacity_start</th>\n",
       "      <th>to_station_name</th>\n",
       "      <th>latitude_end</th>\n",
       "      <th>longitude_end</th>\n",
       "      <th>dpcapacity_end</th>\n",
       "      <th>temperature</th>\n",
       "      <th>visibility</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7147</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>2013-06-28 19:01:00</td>\n",
       "      <td>2013-06-28 19:17:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lake Shore Dr &amp; Monroe St</td>\n",
       "      <td>41.88105</td>\n",
       "      <td>-87.61697</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Michigan Ave &amp; Oak St</td>\n",
       "      <td>41.90096</td>\n",
       "      <td>-87.623777</td>\n",
       "      <td>15.0</td>\n",
       "      <td>73.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>mostlycloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7524</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>2013-06-28 22:53:00</td>\n",
       "      <td>2013-06-28 23:03:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Clinton St &amp; Washington Blvd</td>\n",
       "      <td>41.88338</td>\n",
       "      <td>-87.64117</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Wells St &amp; Walton St</td>\n",
       "      <td>41.89993</td>\n",
       "      <td>-87.634430</td>\n",
       "      <td>19.0</td>\n",
       "      <td>69.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>partlycloudy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trip_id    usertype gender            starttime             stoptime  \\\n",
       "0     7147  Subscriber   Male  2013-06-28 19:01:00  2013-06-28 19:17:00   \n",
       "1     7524  Subscriber   Male  2013-06-28 22:53:00  2013-06-28 23:03:00   \n",
       "\n",
       "   tripduration             from_station_name  latitude_start  \\\n",
       "0           0.0     Lake Shore Dr & Monroe St        41.88105   \n",
       "1           0.0  Clinton St & Washington Blvd        41.88338   \n",
       "\n",
       "   longitude_start  dpcapacity_start        to_station_name  latitude_end  \\\n",
       "0        -87.61697              11.0  Michigan Ave & Oak St      41.90096   \n",
       "1        -87.64117              31.0   Wells St & Walton St      41.89993   \n",
       "\n",
       "   longitude_end  dpcapacity_end  temperature  visibility  wind_speed  \\\n",
       "0     -87.623777            15.0         73.9        10.0        12.7   \n",
       "1     -87.634430            19.0         69.1        10.0         6.9   \n",
       "\n",
       "   precipitation        events  \n",
       "0        -9999.0  mostlycloudy  \n",
       "1        -9999.0  partlycloudy  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.iloc[:2, 5] = 0\n",
    "bikes.head(2)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
